
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["antoine-weill-duflos"],"categories":null,"content":"I am currently working at Haply Robotics, building awesome robots for haptic interaction and more !\nPreviously, I was working in the SRL group at McGill as a Postdoctoral Fellow. My work there involved many aspects of research in haptic.\nAfter obtaining my diploma of engineer from the school of Arts and Metiers, I chose to pursue doctoral studies in haptics and micro-robotics.\nThis PhD was an opportunity for me to discover specific issues related to teleoperation at the micro and nanoscopic scales. It was also an opportunity to enhance my knowledge in mechatronics and haptics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1706392733,"objectID":"e6c5da190f63f968f73c69e8431135d1","permalink":"https://antoine.weill-duflos.fr/en/author/antoine-weill-duflos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/antoine-weill-duflos/","section":"authors","summary":"I am currently working at Haply Robotics, building awesome robots for haptic interaction and more !\nPreviously, I was working in the SRL group at McGill as a Postdoctoral Fellow. My work there involved many aspects of research in haptic.\nAfter obtaining my diploma of engineer from the school of Arts and Metiers, I chose to pursue doctoral studies in haptics and micro-robotics.\nThis PhD was an opportunity for me to discover specific issues related to teleoperation at the micro and nanoscopic scales. It was also an opportunity to enhance my knowledge in mechatronics and haptics.\n","tags":null,"title":"Antoine Weill-Duflos","type":"authors"},{"authors":null,"categories":null,"content":" Git is the most widely used version control system in the world, essential for modern software development. Purpose Git is a distributed version control system designed to handle everything from small to very large projects with speed and efficiency. It allows multiple developers to work on the same codebase simultaneously without conflicts, tracks changes over time, and provides mechanisms for collaboration and code review.\nThis course will teach you how to use Git effectively for collaborative development, with a focus on:\nUnderstanding Git fundamentals - repositories, commits, and basic operations Working with remotes - GitHub and GitLab for collaborative development Mastering branches - creating, merging, and rebasing branches Implementing best practices - feature branch workflow and merge requests Whether you’re a solo developer or part of a large team, understanding Git will help you manage your code more effectively, collaborate with others seamlessly, and maintain a clean, organized project history.\n","date":1744070400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1744070400,"objectID":"2ee1bda79c77aa575e6c2506fb21d511","permalink":"https://antoine.weill-duflos.fr/en/courses/git/","publishdate":"2025-04-08T00:00:00Z","relpermalink":"/en/courses/git/","section":"courses","summary":"Learn how to use Git effectively for collaborative development, including remotes, branches, and best practices.","tags":null,"title":"Understanding Git for Collaborative Development","type":"book"},{"authors":null,"categories":null,"content":"Installation The software can be found on Leapmotion website, download the version that suits your OS.\nWindows is supported on version 3 of the SDK, MacOS and Linux users 1 must install version 2.\nIf everything is working, you should have a new icon in your notification area. If you are taking the HCI class, You have now done everything required before the class. Everything after this will require to plug an USB leapmotion into your computer. You may have to go to the settings to enable the Web applications, once its done you should see an incrementing number of frames just below.\nFor the linux users, Ubuntu/Debian installation is easy, RedHat Fedora requires more work 😞. Other distributions will require more steps… ↩︎\n","date":1571961600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1660311494,"objectID":"228a437e69a186ca0c143a2abccd48ab","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/","publishdate":"2019-10-25T00:00:00Z","relpermalink":"/en/courses/leapmotion/","section":"courses","summary":"Learn how to use javascript Leapjs library to create in air interactions.","tags":null,"title":"How to create Interaction with the LeapMotion","type":"book"},{"authors":null,"categories":null,"content":" Sadly, this is not (yet?) supported on iOS. Purpose This feature can be used for adding vibration feedback to webpages interaction:\nA quick example, taken from here can be seen on this page, to try out the vibration API on your device.\nPlay pattern","date":1571875200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1660311494,"objectID":"7f75946b62b64ad7dfb9d9e427cb74a1","permalink":"https://antoine.weill-duflos.fr/en/courses/haptic/","publishdate":"2019-10-24T00:00:00Z","relpermalink":"/en/courses/haptic/","section":"courses","summary":"Learn how to use HTML5 vibration API to create haptic feedbacks.","tags":null,"title":"How to create Haptic effect in HTML5","type":"book"},{"authors":null,"categories":null,"content":"Git Fundamentals Git is a distributed version control system that tracks changes to files over time. Unlike centralized version control systems, Git gives every developer a complete copy of the repository, including its full history.\nKey Concepts Repository (Repo): A collection of files and their complete history.\n# Initialize a new repository git init # Clone an existing repository git clone https://github.com/username/repository.git Commit: A snapshot of your files at a specific point in time.\n# Stage changes for commit git add filename.txt # Stage all changes git add . # Commit staged changes git commit -m \u0026#34;Descriptive message about changes\u0026#34; Staging Area: A middle ground between your working directory and the repository.\n# Check status of working directory and staging area git status # See differences between working directory and staging area git diff # See differences between staging area and last commit git diff --staged Working with Remotes Remotes are versions of your repository hosted on a server, enabling collaboration with other developers.\nGitHub vs GitLab Both GitHub and GitLab are platforms for hosting Git repositories, but they have some differences:\nGitHub:\nWorld’s largest code hosting platform Strong open-source community Acquired by Microsoft in 2018 Features: Actions (CI/CD), Codespaces, Copilot GitLab:\nComplete DevOps platform Available as self-hosted or cloud-hosted Integrated CI/CD pipeline Features: Built-in issue tracking, wiki, container registry Managing Remotes # List all remote repositories git remote -v # Add a new remote git remote add origin https://github.com/username/repository.git # Change remote URL git remote set-url origin https://github.com/username/new-repository.git # Add multiple remotes (e.g., GitHub and GitLab) git remote add github https://github.com/username/repository.git git remote add gitlab https://gitlab.com/username/repository.git Syncing with Remotes # Download changes from remote without integrating them git fetch origin # Download and integrate changes from remote git pull origin main # Upload local changes to remote git push origin main Best Practices for Remotes Use SSH keys for secure authentication:\n# Generate SSH key ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; # Add to GitHub/GitLab account cat ~/.ssh/id_ed25519.pub Set up multiple remotes for backup and flexibility:\n# Push to multiple remotes git push github main git push gitlab main Use remote tracking branches to simplify commands:\n# Set up tracking git branch --set-upstream-to=origin/main main # Now you can use simplified commands git pull git push Keep remote references clean:\n# Prune deleted remote branches git fetch --prune ","date":1744066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744066800,"objectID":"62e8e9674613dcfdfa87a1457381feed","permalink":"https://antoine.weill-duflos.fr/en/courses/git/basic/","publishdate":"2025-04-08T00:00:00+01:00","relpermalink":"/en/courses/git/basic/","section":"courses","summary":"Git Fundamentals Git is a distributed version control system that tracks changes to files over time. Unlike centralized version control systems, Git gives every developer a complete copy of the repository, including its full history.\nKey Concepts Repository (Repo): A collection of files and their complete history.\n# Initialize a new repository git init # Clone an existing repository git clone https://github.com/username/repository.git Commit: A snapshot of your files at a specific point in time.\n","tags":null,"title":"Git Fundamentals and Remotes","type":"book"},{"authors":[],"categories":[],"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706392733,"objectID":"ffc04b579dbd18778fe10e10525cb3a1","permalink":"https://antoine.weill-duflos.fr/en/project/inverse3/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/en/project/inverse3/","section":"project","summary":"The Haply Inverse3 is a 3-DOF haptic device with great force feedback performances and high portability.","tags":["haptic"],"title":"Haply Inverse3","type":"project"},{"authors":null,"categories":null,"content":"All the informations on the API calls can be found on the official Leapmotion website.\nTo access the leapmotion on a webpage, first import the libs:\n\u0026lt;script src=\u0026#34;leap-0.6.4.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script src=\u0026#34;leap-plugins-0.1.12.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\rLeapJS download link\nleap plugin download link\nThen we create a controller\nvar controller = new Leap.Controller();\rand finally, create and execute the loop:\ncontroller.on(\u0026#39;frame\u0026#39;, function(frame){\r// instructions of your loop\r});\rcontroller.connect();\r","date":1572217200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"cec706efa3babc5dadf4eaeffcdd998a","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/basis/","publishdate":"2019-10-28T00:00:00+01:00","relpermalink":"/en/courses/leapmotion/basis/","section":"courses","summary":"All the informations on the API calls can be found on the official Leapmotion website.\nTo access the leapmotion on a webpage, first import the libs:\n\u003cscript src=\"leap-0.6.4.js\"\u003e\u003c/script\u003e\r\u003cscript src=\"leap-plugins-0.1.12.js\"\u003e\u003c/script\u003e\rLeapJS download link\nleap plugin download link\nThen we create a controller\nvar controller = new Leap.Controller();\rand finally, create and execute the loop:\ncontroller.on('frame', function(frame){\r// instructions of your loop\r});\rcontroller.connect();\r","tags":null,"title":"Basis","type":"book"},{"authors":null,"categories":null,"content":"Fingers: Positions of the tips of the fingers:\n//finger from 0 to 4 are, in order: thumb, index, middle, ring and pinky\rframe.fingers[0].tipPosition\rthumb … index … middle … ring … pinky … The positions can be used to compute distances between the tips.\ndistance = function(a,b) {\rvar x = a[0]-b[0]\rvar y = a[1]-b[1]\rvar z = a[2]-b[2]\rx *= x\ry *= y\rz *= z\rreturn Math.sqrt(x+y+z)\r}\rdistance(frame.fingers[0].tipPosition, frame.fingers[1].tipPosition);\rDistance between the tip of the finger and thumb: …\nHands Position of the Palm of the hand\nframe.hands[0].palmPosition;\rPosition of the first hand: Type of hand (right/left):\nframe.hands[0].type;\rFirst hand I’ve seen is: Indication of pinch:\nframe.hands[0].pinchStrength;\rMacOS/Linux and Windows have a very different interpretation of pinch. For Windows a two finger pinch will put the index close to 1, for MacOS and Linux a closed fist will be required. Pinch index: To investigate other information available, which depends on the version of the Leapmotion software you are running, you can dump the “hands” info to the console.\nconsole.log(frame.hands[0])\r","date":1572217200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"df144c6ee18f9ca3df8fc983fab96ade","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/positions/","publishdate":"2019-10-28T00:00:00+01:00","relpermalink":"/en/courses/leapmotion/positions/","section":"courses","summary":"Fingers: Positions of the tips of the fingers:\n//finger from 0 to 4 are, in order: thumb, index, middle, ring and pinky\rframe.fingers[0].tipPosition\rthumb … index … middle … ring … pinky … The positions can be used to compute distances between the tips.\ndistance = function(a,b) {\rvar x = a[0]-b[0]\rvar y = a[1]-b[1]\rvar z = a[2]-b[2]\rx *= x\ry *= y\rz *= z\rreturn Math.sqrt(x+y+z)\r}\rdistance(frame.fingers[0].tipPosition, frame.fingers[1].tipPosition);\rDistance between the tip of the finger and thumb: …\n","tags":null,"title":"Positions","type":"book"},{"authors":null,"categories":null,"content":"As long as your device support the Vibration API, usage is very simple.\nThe only functions to use is :\nnavigator.vibrate();\rIf you want to make a simple vibration:\n// Vibrate for 300ms\rnavigator.vibrate([300]);\r// or\rnavigator.vibrate(300);\rTry it !\nFor more complex pattern you can pass a pattern of vibrations followed by pauses:\n// \u0026#39;SOS\u0026#39; in morse code\rnavigator.vibrate([50,50,50,50,50,150,150,50,150,50,150,150,50,50,50,50,50]]); Try it !\nSometimes smartphone actuator cannot play fast changes, so here is a slower version:\n// a slower \u0026#39;SOS\u0026#39; in morse code\rnavigator.vibrate([100,100,100,100,100,300,300,100,300,100,300,300,100,100,100,100,100]); Try it !\nTo stop a vibration, just call the function with the value 0:\nnavigator.vibrate(0)\rStart it ! Stop it !\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"db6303582f754809b0aedda51c1aa649","permalink":"https://antoine.weill-duflos.fr/en/courses/haptic/basic/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/haptic/basic/","section":"courses","summary":"As long as your device support the Vibration API, usage is very simple.\nThe only functions to use is :\nnavigator.vibrate();\rIf you want to make a simple vibration:\n// Vibrate for 300ms\rnavigator.vibrate([300]);\r// or\rnavigator.vibrate(300);\rTry it !\nFor more complex pattern you can pass a pattern of vibrations followed by pauses:\n// 'SOS' in morse code\rnavigator.vibrate([50,50,50,50,50,150,150,50,150,50,150,150,50,50,50,50,50]]); Try it !\n","tags":null,"title":"Basic usage","type":"book"},{"authors":null,"categories":null,"content":"Understanding Branches Branches are one of Git’s most powerful features, allowing developers to work on different features or fixes simultaneously without interfering with each other.\nBranch Basics # List all branches (* indicates current branch) git branch # Create a new branch git branch feature-name # Create and switch to a new branch git checkout -b feature-name # Switch to an existing branch git checkout feature-name # Delete a branch (after merging) git branch -d feature-name # Force delete a branch (even if not merged) git branch -D feature-name Branch Visualization Branches in Git can be visualized as separate lines of development that can later be integrated:\nA---B---C feature-branch / D---E---F---G main Integrating Changes: Merge vs. Rebase There are two primary ways to integrate changes from one branch into another: merging and rebasing. Each has its advantages and appropriate use cases.\nMerging Merging creates a new “merge commit” that combines the changes from both branches.\n# Switch to the target branch (e.g., main) git checkout main # Merge changes from feature branch git merge feature-branch Result of merging:\nA---B---C feature-branch / \\ D---E---F---G---H main Advantages of Merging:\nPreserves complete history and chronological order Non-destructive operation (doesn’t change existing commits) Clearly shows when and how features were integrated Best for:\nPublic/shared branches When the branch history is important to preserve When you want to see exactly when a feature was merged Rebasing Rebasing moves or “replays” your branch commits onto the tip of another branch, creating a linear history.\n# Switch to the feature branch git checkout feature-branch # Rebase onto main git rebase main Before rebase:\nA---B---C feature-branch / D---E---F---G main After rebase:\nA\u0026#39;--B\u0026#39;--C\u0026#39; feature-branch / D---E---F---G main Advantages of Rebasing:\nCreates a cleaner, linear project history Eliminates unnecessary merge commits Makes it easier to find bugs with tools like git bisect Best for:\nLocal/private branches before sharing Keeping feature branches up-to-date with main When you want a clean, linear history Choosing Between Merge and Rebase A good rule of thumb:\nRebase your private/local branches to keep them updated with the main branch Merge your feature branches back into the main branch when they’re complete The Golden Rule of Rebasing Never rebase branches that others are working on or that have been pushed to a public repository.\nRebasing changes commit history, which can cause serious problems for collaborators if they’ve based work on those commits.\nAdvanced Branch Operations Cherry-picking Cherry-picking allows you to apply specific commits from one branch to another.\n# Apply a specific commit to current branch git cherry-pick commit-hash Interactive Rebasing Interactive rebasing gives you fine-grained control over your commit history.\n# Start an interactive rebase for the last 3 commits git rebase -i HEAD~3 This opens an editor where you can:\nReorder commits Edit commit messages Combine (squash) commits Split commits Delete commits Stashing Changes Stashing allows you to temporarily save changes without committing them.\n# Stash current changes git stash # List stashes git stash list # Apply most recent stash git stash apply # Apply specific stash git stash apply stash@{2} # Remove most recent stash after applying git stash pop # Clear all stashes git stash clear ","date":1744066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744066800,"objectID":"12e3b0193e68680130419ab09379f417","permalink":"https://antoine.weill-duflos.fr/en/courses/git/branches/","publishdate":"2025-04-08T00:00:00+01:00","relpermalink":"/en/courses/git/branches/","section":"courses","summary":"Understanding Branches Branches are one of Git’s most powerful features, allowing developers to work on different features or fixes simultaneously without interfering with each other.\nBranch Basics # List all branches (* indicates current branch) git branch # Create a new branch git branch feature-name # Create and switch to a new branch git checkout -b feature-name # Switch to an existing branch git checkout feature-name # Delete a branch (after merging) git branch -d feature-name # Force delete a branch (even if not merged) git branch -D feature-name Branch Visualization Branches in Git can be visualized as separate lines of development that can later be integrated:\n","tags":null,"title":"Branches and Integration","type":"book"},{"authors":null,"categories":null,"content":"Try to create vibrations patterns matching different types of content.\nWarning !\nYou won !\nYou lost !\nHurry !\nYou can start with the following code:\n\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;Vibrations pattern example\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;script\u0026gt;function warning() {\rnavigator.vibrate(1);\r}\r\u0026lt;/script\u0026gt;\r\u0026lt;button onclick=\u0026#34;warning()\u0026#34;\u0026gt;Warning !\u0026lt;/button\u0026gt;\r\u0026lt;script\u0026gt;function win() {\rnavigator.vibrate(1);\r}\r\u0026lt;/script\u0026gt;\r\u0026lt;button onclick=\u0026#34;win()\u0026#34;\u0026gt;You won !\u0026lt;/button\u0026gt;\r\u0026lt;script\u0026gt;function loose() {\rnavigator.vibrate(1);\r}\r\u0026lt;/script\u0026gt;\r\u0026lt;button onclick=\u0026#34;loose()\u0026#34;\u0026gt;You lost !\u0026lt;/button\u0026gt;\r\u0026lt;script\u0026gt;function hurry() {\rnavigator.vibrate(1);\r}\r\u0026lt;/script\u0026gt;\r\u0026lt;button onclick=\u0026#34;hurry()\u0026#34;\u0026gt;Hurry !\u0026lt;/button\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\r","date":1572390000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"e690c6bd17cb544f77ef7886af01c818","permalink":"https://antoine.weill-duflos.fr/en/courses/haptic/exercise/","publishdate":"2019-10-30T00:00:00+01:00","relpermalink":"/en/courses/haptic/exercise/","section":"courses","summary":"Try to create vibrations patterns matching different types of content.\nWarning !\nYou won !\nYou lost !\nHurry !\nYou can start with the following code:\n\u003chtml\u003e\r\u003chead\u003e\r\u003ctitle\u003eVibrations pattern example\u003c/title\u003e\r\u003c/head\u003e\r\u003cbody\u003e\r\u003cscript\u003efunction warning() {\rnavigator.vibrate(1);\r}\r\u003c/script\u003e\r\u003cbutton onclick=\"warning()\"\u003eWarning !\u003c/button\u003e\r\u003cscript\u003efunction win() {\rnavigator.vibrate(1);\r}\r\u003c/script\u003e\r\u003cbutton onclick=\"win()\"\u003eYou won !\u003c/button\u003e\r\u003cscript\u003efunction loose() {\rnavigator.vibrate(1);\r}\r\u003c/script\u003e\r\u003cbutton onclick=\"loose()\"\u003eYou lost !\u003c/button\u003e\r\u003cscript\u003efunction hurry() {\rnavigator.vibrate(1);\r}\r\u003c/script\u003e\r\u003cbutton onclick=\"hurry()\"\u003eHurry !\u003c/button\u003e\r\u003c/body\u003e\r\u003c/html\u003e\r","tags":null,"title":"Activity","type":"book"},{"authors":null,"categories":null,"content":" Unfortunately this is deprecated in the current version of the Windows build and will not work… To get the gesture information, the easiest way is to print the info in the console.\nframe.gestures.forEach(function(gesture, index) {\rconsole.log(gesture)\r});\rTypes of gestures There are 4 types of recognized gestures:\nCircle : 0 Swipe : 0 keyTap : 0 Screentap : 0 ","date":1572217200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"0731985f3a8dde309e316aa00ba87869","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/gestures/","publishdate":"2019-10-28T00:00:00+01:00","relpermalink":"/en/courses/leapmotion/gestures/","section":"courses","summary":" Unfortunately this is deprecated in the current version of the Windows build and will not work… To get the gesture information, the easiest way is to print the info in the console.\nframe.gestures.forEach(function(gesture, index) {\rconsole.log(gesture)\r});\rTypes of gestures There are 4 types of recognized gestures:\nCircle : 0 Swipe : 0 keyTap : 0 Screentap : 0 ","tags":null,"title":"Gestures","type":"book"},{"authors":null,"categories":null,"content":"The script is based on a simple ball collision simulation.\nWhen a ball hit the wall, it triggers a vibration. The script uses the smartphone accelerometer to change the direction of the gravity force.\nPress button to reset.\nReset\radd ball\rvar canvas = document.querySelector(\u0026#39;canvas\u0026#39;);\rvar pen = canvas.getContext(\u0026#39;2d\u0026#39;);\rconst W = canvas.width;\rconst H = canvas.height;\rvar numBalls = 1;\rvar grav = [0, -0.1];\rfunction Ball(x, y, dx, dy, r) {\rthis.x = x;\rthis.y = y;\rthis.dx = dx;\rthis.dy = dy;\rthis.r = r;\rthis.color = \u0026#39;hsl(\u0026#39; + Math.random() * 360 + \u0026#39;,90%,50%)\u0026#39;;\rthis.draw = function () {\rpen.fillStyle = this.color;\rpen.beginPath();\rpen.arc(this.x, this.y, this.r, 0, 2 * Math.PI);\rpen.fill();\r};\rthis.update = function () {\rthis.x += this.dx;\rthis.y += this.dy;\rthis.dx += grav[0];\rthis.dy -= grav[1];\rif (this.x \u0026gt; W - this.r) {\rthis.x = W - this.r;\rif (this.dx \u0026gt; 4)\rnavigator.vibrate(10);\r// We made the phone vibrate because it had sufficent velocity\rthis.dx *= -0.5;\r} else if (this.x \u0026lt; this.r) {\rthis.x = this.r;\rif (this.dx \u0026lt; 4)\rnavigator.vibrate(10);\rthis.dx *= -0.5;\r}\rif (this.y \u0026gt; H - this.r) {\rthis.y = H - this.r;\rif (this.dy \u0026gt; 4)\rnavigator.vibrate(10);\rthis.dy *= -0.5;\r} else if (this.y \u0026lt; this.r) {\rthis.y = this.r + 1;\rif (this.dy \u0026lt; 4)\rnavigator.vibrate(10);\rthis.dy *= -0.5;\r}\rthis.draw();\r};\r}\rvar balls = [];\rfunction reset() {\rballs = [];\rfor (var i = 0; i \u0026lt; numBalls; i++) {\rvar x = Math.random() * W;\rvar y = Math.random() * H;\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(x, y, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\r}\r}\rreset();\rvar output = document.querySelector(\u0026#39;.output\u0026#39;);\rfunction handleOrientation(event) {\rvar x = event.beta; // In degree in the range [-180,180]\rvar y = event.gamma; // In degree in the range [-90,90]\routput.innerHTML = \u0026#34;beta : \u0026#34; + x + \u0026#34;\\n\u0026#34;;\routput.innerHTML += \u0026#34;gamma: \u0026#34; + y + \u0026#34;\\n\u0026#34;;\rif (x \u0026gt; 90) { x = 90};\rif (x \u0026lt; -90) { x = -90};\rgrav[1] = -x/90;\rgrav[0] = y/90;\r}\rwindow.addEventListener(\u0026#39;deviceorientation\u0026#39;, handleOrientation, false);\rwindow.addEventListener(\u0026#39;keydown\u0026#39;, function (key) {\rif (key.code === \u0026#39;Space\u0026#39;) {\rreset();\r}\r});\rvar mouseDown = false;\rvar cooldown = 0;\rvar mouse = {\rx: undefined,\ry: undefined };\rcanvas.addEventListener(\u0026#39;mousedown\u0026#39;, function (event) {\rmouseDown = true;\r});\rcanvas.addEventListener(\u0026#39;mouseup\u0026#39;, function (event) {\rmouseDown = false;\r});\rcanvas.addEventListener(\u0026#39;mousemove\u0026#39;, function (event) {\rmouse.x = event.x - 15;\rmouse.y = event.y - 15;\r});\rfunction addball() {\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(0, 0, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\r}\rfunction animateb() {\rpen.clearRect(0, 0, W, H);\rcooldown++;\rif (mouseDown \u0026amp;\u0026amp; cooldown \u0026gt; 2) {\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(mouse.x, mouse.y, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\rcooldown = 0;\r}\rfor (var ball of balls) {\rball.update();\rfor (var ball2 of balls) {//Not the most efficient way to check every pair, but this is just a rough version\rif (ball !== ball2) {\rvar collision = checkCollision(ball, ball2);\rif (collision[0]) {\radjustPositions(ball, ball2, collision[1]);\rresolveCollision(ball, ball2);\r}\r}\r}\r}\rrequestAnimationFrame(animateb);\r}\ranimateb();\rfunction checkCollision(ballA, ballB) {\rvar rSum = ballA.r + ballB.r;\rvar dx = ballB.x - ballA.x;\rvar dy = ballB.y - ballA.y;\rreturn [rSum * rSum \u0026gt; dx * dx + dy * dy, rSum - Math.sqrt(dx * dx + dy * dy)];\r}\rfunction resolveCollision(ballA, ballB) {\rvar relVel = [ballB.dx - ballA.dx, ballB.dy - ballA.dy];\rvar norm = [ballB.x - ballA.x, ballB.y - ballA.y];\rvar mag = Math.sqrt(norm[0] * norm[0] + norm[1] * norm[1]);\rnorm = [norm[0] / mag, norm[1] / mag];\rvar velAlongNorm = relVel[0] * norm[0] + relVel[1] * norm[1];\rif (velAlongNorm \u0026gt; 0)\rreturn;\rvar bounce = 0.7;\rvar j = -(1 + bounce) * velAlongNorm;\rj /= 1 / ballA.r + 1 / ballB.r;\rvar impulse = [j * norm[0], j * norm[1]];\rballA.dx -= 1 / ballA.r * impulse[0];\rballA.dy -= 1 / ballA.r * impulse[1];\rballB.dx += 1 / ballB.r * impulse[0];\rballB.dy += 1 / ballB.r * impulse[1];\rvit = relVel[0] + relVel[1]\r}\rfunction adjustPositions(ballA, ballB, depth) {//Inefficient implementation for now\rconst percent = 0.2;\rconst slop = 0.01;\rvar correction = Math.max(depth - slop, 0) / (1 / ballA.r + 1 / ballB.r) * percent;\rvar norm = [ballB.x - ballA.x, ballB.y - ballA.y];\rvar mag = Math.sqrt(norm[0] * norm[0] + norm[1] * norm[1]);\rnorm = [norm[0] / mag, norm[1] / mag];\rcorrection = [correction * norm[0], correction * norm[1]];\rballA.x -= 1 / ballA.r * correction[0];\rballA.y -= 1 / ballA.r * correction[1];\rballB.x += 1 / ballB.r * correction[0];\rballB.y += 1 / ballB.r * correction[1];\r}\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"17f4041829f7a611d4109fea718e6c72","permalink":"https://antoine.weill-duflos.fr/en/courses/haptic/interactions/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/haptic/interactions/","section":"courses","summary":"The script is based on a simple ball collision simulation.\nWhen a ball hit the wall, it triggers a vibration. The script uses the smartphone accelerometer to change the direction of the gravity force.\nPress button to reset.\nReset\radd ball\rvar canvas = document.querySelector('canvas');\rvar pen = canvas.getContext('2d');\rconst W = canvas.width;\rconst H = canvas.height;\rvar numBalls = 1;\rvar grav = [0, -0.1];\rfunction Ball(x, y, dx, dy, r) {\rthis.x = x;\rthis.y = y;\rthis.dx = dx;\rthis.dy = dy;\rthis.r = r;\rthis.color = 'hsl(' + Math.random() * 360 + ',90%,50%)';\rthis.draw = function () {\rpen.fillStyle = this.color;\rpen.beginPath();\rpen.arc(this.x, this.y, this.r, 0, 2 * Math.PI);\rpen.fill();\r};\rthis.update = function () {\rthis.x += this.dx;\rthis.y += this.dy;\rthis.dx += grav[0];\rthis.dy -= grav[1];\rif (this.x \u003e W - this.r) {\rthis.x = W - this.r;\rif (this.dx \u003e 4)\rnavigator.vibrate(10);\r// We made the phone vibrate because it had sufficent velocity\rthis.dx *= -0.5;\r} else if (this.x \u003c this.r) {\rthis.x = this.r;\rif (this.dx \u003c 4)\rnavigator.vibrate(10);\rthis.dx *= -0.5;\r}\rif (this.y \u003e H - this.r) {\rthis.y = H - this.r;\rif (this.dy \u003e 4)\rnavigator.vibrate(10);\rthis.dy *= -0.5;\r} else if (this.y \u003c this.r) {\rthis.y = this.r + 1;\rif (this.dy \u003c 4)\rnavigator.vibrate(10);\rthis.dy *= -0.5;\r}\rthis.draw();\r};\r}\rvar balls = [];\rfunction reset() {\rballs = [];\rfor (var i = 0; i \u003c numBalls; i++) {\rvar x = Math.random() * W;\rvar y = Math.random() * H;\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(x, y, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\r}\r}\rreset();\rvar output = document.querySelector('.output');\rfunction handleOrientation(event) {\rvar x = event.beta; // In degree in the range [-180,180]\rvar y = event.gamma; // In degree in the range [-90,90]\routput.innerHTML = \"beta : \" + x + \"\\n\";\routput.innerHTML += \"gamma: \" + y + \"\\n\";\rif (x \u003e 90) { x = 90};\rif (x \u003c -90) { x = -90};\rgrav[1] = -x/90;\rgrav[0] = y/90;\r}\rwindow.addEventListener('deviceorientation', handleOrientation, false);\rwindow.addEventListener('keydown', function (key) {\rif (key.code === 'Space') {\rreset();\r}\r});\rvar mouseDown = false;\rvar cooldown = 0;\rvar mouse = {\rx: undefined,\ry: undefined };\rcanvas.addEventListener('mousedown', function (event) {\rmouseDown = true;\r});\rcanvas.addEventListener('mouseup', function (event) {\rmouseDown = false;\r});\rcanvas.addEventListener('mousemove', function (event) {\rmouse.x = event.x - 15;\rmouse.y = event.y - 15;\r});\rfunction addball() {\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(0, 0, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\r}\rfunction animateb() {\rpen.clearRect(0, 0, W, H);\rcooldown++;\rif (mouseDown \u0026\u0026 cooldown \u003e 2) {\rvar r = Math.random() * 20 + 10;\rballs.push(new Ball(mouse.x, mouse.y, Math.random() * 10 - 5, Math.random() * 10 - 5, r));\rcooldown = 0;\r}\rfor (var ball of balls) {\rball.update();\rfor (var ball2 of balls) {//Not the most efficient way to check every pair, but this is just a rough version\rif (ball !== ball2) {\rvar collision = checkCollision(ball, ball2);\rif (collision[0]) {\radjustPositions(ball, ball2, collision[1]);\rresolveCollision(ball, ball2);\r}\r}\r}\r}\rrequestAnimationFrame(animateb);\r}\ranimateb();\rfunction checkCollision(ballA, ballB) {\rvar rSum = ballA.r + ballB.r;\rvar dx = ballB.x - ballA.x;\rvar dy = ballB.y - ballA.y;\rreturn [rSum * rSum \u003e dx * dx + dy * dy, rSum - Math.sqrt(dx * dx + dy * dy)];\r}\rfunction resolveCollision(ballA, ballB) {\rvar relVel = [ballB.dx - ballA.dx, ballB.dy - ballA.dy];\rvar norm = [ballB.x - ballA.x, ballB.y - ballA.y];\rvar mag = Math.sqrt(norm[0] * norm[0] + norm[1] * norm[1]);\rnorm = [norm[0] / mag, norm[1] / mag];\rvar velAlongNorm = relVel[0] * norm[0] + relVel[1] * norm[1];\rif (velAlongNorm \u003e 0)\rreturn;\rvar bounce = 0.7;\rvar j = -(1 + bounce) * velAlongNorm;\rj /= 1 / ballA.r + 1 / ballB.r;\rvar impulse = [j * norm[0], j * norm[1]];\rballA.dx -= 1 / ballA.r * impulse[0];\rballA.dy -= 1 / ballA.r * impulse[1];\rballB.dx += 1 / ballB.r * impulse[0];\rballB.dy += 1 / ballB.r * impulse[1];\rvit = relVel[0] + relVel[1]\r}\rfunction adjustPositions(ballA, ballB, depth) {//Inefficient implementation for now\rconst percent = 0.2;\rconst slop = 0.01;\rvar correction = Math.max(depth - slop, 0) / (1 / ballA.r + 1 / ballB.r) * percent;\rvar norm = [ballB.x - ballA.x, ballB.y - ballA.y];\rvar mag = Math.sqrt(norm[0] * norm[0] + norm[1] * norm[1]);\rnorm = [norm[0] / mag, norm[1] / mag];\rcorrection = [correction * norm[0], correction * norm[1]];\rballA.x -= 1 / ballA.r * correction[0];\rballA.y -= 1 / ballA.r * correction[1];\rballB.x += 1 / ballB.r * correction[0];\rballB.y += 1 / ballB.r * correction[1];\r}\r","tags":null,"title":"Application example","type":"book"},{"authors":null,"categories":null,"content":"Feature Branch Workflow The feature branch workflow is a Git workflow that promotes collaboration while ensuring the main branch always contains production-quality code.\nCore Principles Main branch is always deployable\nThe main branch (often called main or master) should always contain stable, production-ready code Never commit directly to main in a collaborative environment Feature development happens in dedicated branches\nEach new feature or bugfix gets its own branch Branches are created from the latest main branch Work is isolated until the feature is complete Integration through merge/pull requests\nChanges are integrated back to main through merge requests (GitLab) or pull requests (GitHub) This enables code review and discussion before integration Automated tests can be run before merging Workflow Steps main branch: ----o----o----o----o----o----o----o---- \\ / feature branch: o----o----o----o----o Update main branch\ngit checkout main git pull origin main Create a feature branch\ngit checkout -b feature/user-authentication Work on the feature\n# Make changes, then commit git add . git commit -m \u0026#34;Add user login form\u0026#34; # Make more changes git add . git commit -m \u0026#34;Add password validation\u0026#34; Keep your feature branch updated\n# Option 1: Merge (safer) git checkout feature/user-authentication git merge main # Option 2: Rebase (cleaner history) git checkout feature/user-authentication git rebase main Push your feature branch\ngit push origin feature/user-authentication Create a merge/pull request\nDone through the GitLab/GitHub web interface Assign reviewers Add description of changes Address review feedback\n# Make requested changes git add . git commit -m \u0026#34;Address review feedback\u0026#34; git push origin feature/user-authentication Merge into main\nAfter approval, merge through the web interface Or use command line: git checkout main git merge feature/user-authentication git push origin main Delete the feature branch\n# Delete local branch git branch -d feature/user-authentication # Delete remote branch git push origin --delete feature/user-authentication Merge/Pull Requests Best Practices Merge requests (GitLab) and pull requests (GitHub) are powerful collaboration tools that facilitate code review and discussion before changes are integrated.\nCreating Effective Merge Requests Keep changes focused and small\nSmaller changes are easier to review Aim for less than 400 lines of code per request Each merge request should address a single concern Write descriptive titles and descriptions\nTitle: Brief summary of what the change does Description: Explain the why, not just the what Include links to related issues or requirements Add appropriate labels and assignees\nUse labels to categorize the request (bug, feature, etc.) Assign to appropriate reviewers Include tests and documentation\nAdd tests that verify your changes Update documentation if necessary Example Merge Request Template ## Description Brief description of the changes ## Related Issues - #123 Feature request - #456 Bug report ## Type of Change - [ ] Bug fix - [ ] New feature - [ ] Breaking change - [ ] Documentation update ## How Has This Been Tested? Describe the tests you ran ## Checklist - [ ] My code follows the project\u0026#39;s style guidelines - [ ] I have added tests that prove my fix/feature works - [ ] New and existing tests pass - [ ] Documentation has been updated Reviewing Code Be thorough but respectful\nFocus on the code, not the person Ask questions rather than making demands Provide constructive feedback Check for:\nFunctionality: Does it work as expected? Code quality: Is it maintainable and readable? Tests: Are there sufficient tests? Security: Are there any vulnerabilities? Performance: Will it cause performance issues? Use inline comments for specific issues\nBe specific about what needs to change Explain why the change is needed Advanced Workflow Concepts Continuous Integration (CI) Set up CI pipelines to automatically:\nRun tests Check code style Build the application Deploy to staging environments # Example .gitlab-ci.yml stages: - test - build - deploy test: stage: test script: - npm install - npm test build: stage: build script: - npm run build artifacts: paths: - dist/ deploy: stage: deploy script: - deploy-script.sh only: - main Protected Branches Configure protected branches in GitLab/GitHub to:\nPrevent direct pushes to important branches Require merge requests for all changes Enforce code review approvals Require CI pipeline to pass before merging Release Workflow For more structured releases:\nMaintain a develop branch\nFeature branches merge into develop Develop contains the latest development changes Create release branches\ngit checkout develop git checkout -b release/v1.2.0 Stabilize the release\nOnly bugfixes go into release branches No new features Merge to main and tag\ngit checkout main git merge release/v1.2.0 git tag -a v1.2.0 -m \u0026#34;Version 1.2.0\u0026#34; git push origin main --tags Merge back to develop\ngit checkout develop git merge release/v1.2.0 git push …","date":1744066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744066800,"objectID":"a8d89dc032690144c76b613fd3ffb0e3","permalink":"https://antoine.weill-duflos.fr/en/courses/git/workflow/","publishdate":"2025-04-08T00:00:00+01:00","relpermalink":"/en/courses/git/workflow/","section":"courses","summary":"Feature Branch Workflow The feature branch workflow is a Git workflow that promotes collaboration while ensuring the main branch always contains production-quality code.\nCore Principles Main branch is always deployable\nThe main branch (often called main or master) should always contain stable, production-ready code Never commit directly to main in a collaborative environment Feature development happens in dedicated branches\nEach new feature or bugfix gets its own branch Branches are created from the latest main branch Work is isolated until the feature is complete Integration through merge/pull requests\n","tags":null,"title":"Feature Development Workflow","type":"book"},{"authors":null,"categories":null,"content":"var cats = {};\rLeap.loop(function(frame) {\rframe.hands.forEach(function(hand, index) {\rvar cat = ( cats[index] || (cats[index] = new Cat()) );\rcat.setTransform(hand.screenPosition(), hand.roll());\r});\r}).use(\u0026#39;screenPosition\u0026#39;, {scale: 0.25});\rvar Cat = function() {\rvar cat = this;\rvar img = document.createElement(\u0026#39;img\u0026#39;);\rimg.src = \u0026#39;https://s3-us-west-2.amazonaws.com/s.cdpn.io/109794/cat_2.png\u0026#39;;\rimg.style.position = \u0026#39;absolute\u0026#39;;\rimg.onload = function () {\rcat.setTransform([window.innerWidth/2,window.innerHeight/2], 0);\rdocument.body.appendChild(img);\r}\rcat.setTransform = function(position, rotation) {\rimg.style.left = position[0] - img.width / 2 + \u0026#39;px\u0026#39;;\rimg.style.top = position[1] - img.height / 2 + \u0026#39;px\u0026#39;;\rimg.style.transform = \u0026#39;rotate(\u0026#39; + -rotation + \u0026#39;rad)\u0026#39;;\rimg.style.webkitTransform = img.style.MozTransform = img.style.msTransform =\rimg.style.OTransform = img.style.transform;\r};\r};\rcats[0] = new Cat();\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"4cbcd2457ce1d937835d1142844ed7ab","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/zcats/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/leapmotion/zcats/","section":"courses","summary":"var cats = {};\rLeap.loop(function(frame) {\rframe.hands.forEach(function(hand, index) {\rvar cat = ( cats[index] || (cats[index] = new Cat()) );\rcat.setTransform(hand.screenPosition(), hand.roll());\r});\r}).use('screenPosition', {scale: 0.25});\rvar Cat = function() {\rvar cat = this;\rvar img = document.createElement('img');\rimg.src = 'https://s3-us-west-2.amazonaws.com/s.cdpn.io/109794/cat_2.png';\rimg.style.position = 'absolute';\rimg.onload = function () {\rcat.setTransform([window.innerWidth/2,window.innerHeight/2], 0);\rdocument.body.appendChild(img);\r}\rcat.setTransform = function(position, rotation) {\rimg.style.left = position[0] - img.width / 2 + 'px';\rimg.style.top = position[1] - img.height / 2 + 'px';\rimg.style.transform = 'rotate(' + -rotation + 'rad)';\rimg.style.webkitTransform = img.style.MozTransform = img.style.msTransform =\rimg.style.OTransform = img.style.transform;\r};\r};\rcats[0] = new Cat();\r","tags":null,"title":"Cats","type":"book"},{"authors":null,"categories":null,"content":"Hands-on Git Exercises Practice these exercises to reinforce your understanding of Git workflows and collaboration.\nExercise 1: Setting Up a Repository with Multiple Remotes Create a new repository on both GitHub and GitLab Initialize a local repository and add both remotes Create a README.md file and push it to both remotes Start with this template:\n# Initialize local repository mkdir git-practice cd git-practice git init # Create README file echo \u0026#34;# Git Practice Repository\u0026#34; \u0026gt; README.md git add README.md git commit -m \u0026#34;Initial commit\u0026#34; # Add remotes (replace with your own URLs) git remote add github https://github.com/username/git-practice.git git remote add gitlab https://gitlab.com/username/git-practice.git # Push to both remotes git push github main git push gitlab main Exercise 2: Feature Branch Development Create a feature branch from main Make several commits to the feature branch Keep your feature branch updated with changes from main Create a merge request Follow these steps:\n# Make sure you\u0026#39;re on main and it\u0026#39;s up to date git checkout main git pull origin main # Create and switch to a feature branch git checkout -b feature/add-documentation # Make changes and commit echo \u0026#34;## Installation\u0026#34; \u0026gt;\u0026gt; README.md echo \u0026#34;Run \\`npm install\\` to install dependencies.\u0026#34; \u0026gt;\u0026gt; README.md git add README.md git commit -m \u0026#34;Add installation instructions\u0026#34; # Make more changes echo \u0026#34;## Usage\u0026#34; \u0026gt;\u0026gt; README.md echo \u0026#34;Run \\`npm start\\` to start the application.\u0026#34; \u0026gt;\u0026gt; README.md git add README.md git commit -m \u0026#34;Add usage instructions\u0026#34; # Update feature branch with changes from main (if any) git checkout main git pull origin main git checkout feature/add-documentation git rebase main # Push feature branch to remote git push origin feature/add-documentation # Now create a merge request through the GitHub/GitLab web interface Exercise 3: Resolving Merge Conflicts Create two branches that modify the same file Merge one branch into main Try to merge the second branch and resolve the conflicts Try this scenario:\n# Start from main git checkout main # Create first feature branch git checkout -b feature/add-contributing echo \u0026#34;## Contributing\u0026#34; \u0026gt;\u0026gt; README.md echo \u0026#34;Please follow the code style guidelines.\u0026#34; \u0026gt;\u0026gt; README.md git add README.md git commit -m \u0026#34;Add contributing guidelines\u0026#34; git checkout main git merge feature/add-contributing git push origin main # Create second feature branch (from earlier main state) git checkout -b feature/add-license echo \u0026#34;## License\u0026#34; \u0026gt;\u0026gt; README.md echo \u0026#34;This project is licensed under MIT.\u0026#34; \u0026gt;\u0026gt; README.md git add README.md git commit -m \u0026#34;Add license information\u0026#34; # Try to merge - this will cause a conflict git checkout main git merge feature/add-license # Resolve the conflict manually, then git add README.md git commit -m \u0026#34;Merge feature/add-license, resolve conflicts\u0026#34; git push origin main Exercise 4: Interactive Rebasing Create a feature branch with several small commits Use interactive rebasing to clean up the commit history Push the cleaned-up branch Follow these steps:\n# Create a feature branch git checkout -b feature/api-integration # Make several small commits echo \u0026#34;function fetchData() {\u0026#34; \u0026gt; api.js echo \u0026#34; // TODO: Implement\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34;}\u0026#34; \u0026gt;\u0026gt; api.js git add api.js git commit -m \u0026#34;Add fetchData function skeleton\u0026#34; echo \u0026#34;function fetchData() {\u0026#34; \u0026gt; api.js echo \u0026#34; return fetch(\u0026#39;https://api.example.com/data\u0026#39;)\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34; .then(response =\u0026gt; response.json());\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34;}\u0026#34; \u0026gt;\u0026gt; api.js git add api.js git commit -m \u0026#34;Implement fetchData function\u0026#34; echo \u0026#34;function fetchData() {\u0026#34; \u0026gt; api.js echo \u0026#34; return fetch(\u0026#39;https://api.example.com/data\u0026#39;)\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34; .then(response =\u0026gt; response.json())\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34; .catch(error =\u0026gt; console.error(\u0026#39;Error fetching data:\u0026#39;, error));\u0026#34; \u0026gt;\u0026gt; api.js echo \u0026#34;}\u0026#34; \u0026gt;\u0026gt; api.js git add api.js git commit -m \u0026#34;Add error handling to fetchData\u0026#34; # Use interactive rebase to clean up commits git rebase -i HEAD~3 # In the editor, change the second and third commits from \u0026#34;pick\u0026#34; to \u0026#34;squash\u0026#34; # Save and close, then edit the commit message # After rebasing, force push (only for private branches!) git push origin feature/api-integration --force Exercise 5: Creating a Complete Pull Request Identify a small improvement for an open-source project Fork the repository Create a feature branch with your improvement Submit a pull request with proper documentation This exercise should be done on a real GitHub/GitLab repository:\n# Fork the repository through the GitHub/GitLab interface # Clone your fork git clone https://github.com/your-username/project.git cd project # Create a feature branch git checkout -b fix/update-readme # Make your changes # Edit files as needed # Commit your changes git add . git commit -m \u0026#34;Update README with clearer installation instructions\u0026#34; # Push to your fork git push origin fix/update-readme # Create a pull request through the GitHub/GitLab interface # Include a detailed description of your changes ","date":1744066800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744066800,"objectID":"e55c3976efd6d612a8ad0de2593041c1","permalink":"https://antoine.weill-duflos.fr/en/courses/git/exercise/","publishdate":"2025-04-08T00:00:00+01:00","relpermalink":"/en/courses/git/exercise/","section":"courses","summary":"Hands-on Git Exercises Practice these exercises to reinforce your understanding of Git workflows and collaboration.\nExercise 1: Setting Up a Repository with Multiple Remotes Create a new repository on both GitHub and GitLab Initialize a local repository and add both remotes Create a README.md file and push it to both remotes Start with this template:\n# Initialize local repository mkdir git-practice cd git-practice git init # Create README file echo \"# Git Practice Repository\" \u003e README.md git add README.md git commit -m \"Initial commit\" # Add remotes (replace with your own URLs) git remote add github https://github.com/username/git-practice.git git remote add gitlab https://gitlab.com/username/git-practice.git # Push to both remotes git push github main git push gitlab main Exercise 2: Feature Branch Development Create a feature branch from main Make several commits to the feature branch Keep your feature branch updated with changes from main Create a merge request Follow these steps:\n","tags":null,"title":"Activity","type":"book"},{"authors":null,"categories":null,"content":"var volume = 0\rvar pitch = 0\rvar context = new AudioContext()\rvar o = context.createOscillator()\rvar g = context.createGain()\ro.connect(g)\rg.connect(context.destination)\rg.gain.value = 0.0\ro.start(0)\rLeap.loop(function(frame) {\rframe.hands.forEach(function(hand, index) {\rif (hand.type == \u0026#34;left\u0026#34;)\r{\rvolume = -1 *hand.screenPosition()[1] / 200.0\rg.gain.value = volume\r}\relse {\rpitch = hand.screenPosition()[2]\ro.frequency.value = pitch/2.0+440\r}\r});\r}).use(\u0026#39;screenPosition\u0026#39;);\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"0f972c1862a7537cca9e1ae6d5c0eb89","permalink":"https://antoine.weill-duflos.fr/en/courses/leapmotion/theremin/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/leapmotion/theremin/","section":"courses","summary":"var volume = 0\rvar pitch = 0\rvar context = new AudioContext()\rvar o = context.createOscillator()\rvar g = context.createGain()\ro.connect(g)\rg.connect(context.destination)\rg.gain.value = 0.0\ro.start(0)\rLeap.loop(function(frame) {\rframe.hands.forEach(function(hand, index) {\rif (hand.type == \"left\")\r{\rvolume = -1 *hand.screenPosition()[1] / 200.0\rg.gain.value = volume\r}\relse {\rpitch = hand.screenPosition()[2]\ro.frequency.value = pitch/2.0+440\r}\r});\r}).use('screenPosition');\r","tags":null,"title":"Leap-theremin","type":"book"},{"authors":null,"categories":["Technical Guides"],"content":"Introduction Email delivery is a complex but essential aspect of modern communication infrastructure. Whether you’re managing emails for a small business or a large organization, understanding the underlying concepts can help you improve deliverability, security, and overall email performance.\nThis guide covers the fundamental aspects of email delivery, from the basic SMTP protocol to advanced authentication methods and reputation management strategies. We’ll use simple analogies to explain complex concepts and provide practical recommendations for implementation.\nSMTP Protocol Basics Simple Mail Transfer Protocol (SMTP) is the foundation of email delivery. It’s a communication protocol for electronic mail transmission, working like a postal service for the internet.\nWhen you send an email, your email client connects to an SMTP server using TCP port 25, 587, or 465 (for SSL/TLS). The client provides the sender, recipient, and message content to the server.\nThe SMTP server then determines how to route the message, looking up the recipient’s domain MX (Mail Exchange) records through DNS to find the receiving mail server.\nKey SMTP Commands: HELO/EHLO: Identifies the sending mail server MAIL FROM: Specifies the sender’s address RCPT TO: Specifies the recipient’s address DATA: Begins the transfer of the message content QUIT: Ends the session Email Authentication Email authentication protocols help verify the identity of senders and protect against spoofing and phishing. Let’s explore the three main authentication methods using the classic “Alice and Bob” analogy.\nSPF (Sender Policy Framework) Think of SPF as a guest list for your domain’s mailroom. It specifies which mail servers are authorized to send emails on behalf of your domain.\nHow it works: The domain owner publishes a list of authorized sending servers in a DNS TXT record.\nStrengths:\nEasy to implement Prevents direct domain spoofing Widely supported Weaknesses:\nDoesn’t verify email content Breaks with forwarding No reporting mechanism DKIM (DomainKeys Identified Mail) DKIM is like a wax seal on an envelope. It adds a digital signature to emails that can be verified using a public key published in DNS.\nHow it works: The sending server adds a digital signature to the email header, which receiving servers can verify using the public key in DNS.\nStrengths:\nVerifies email content integrity Survives forwarding Cryptographically secure Weaknesses:\nComplex to implement No reporting mechanism Doesn’t prevent all spoofing DMARC (Domain-based Message Authentication, Reporting \u0026amp; Conformance) DMARC ties SPF and DKIM together, providing instructions on what to do when authentication fails and offering reporting.\nHow it works: DMARC specifies what to do when SPF or DKIM checks fail and provides a reporting mechanism.\nStrengths:\nProvides reporting Clear policy enforcement Combines SPF and DKIM Weaknesses:\nRequires SPF and DKIM to be set up first More complex to implement Requires ongoing monitoring Why Use All Three? Each protocol addresses different aspects of email authentication:\nSPF verifies the sending server is authorized DKIM ensures message integrity and authenticity DMARC provides policy enforcement and reporting Together, they create a comprehensive authentication system that significantly improves email security and deliverability.\nReal-World Scenario: If you only implement SPF, attackers can still forge emails that appear to come from your domain by manipulating the “From” header. DKIM helps prevent this by signing the headers, and DMARC ties everything together with clear policies on what to do when authentication fails.\nDNS and Domain Hierarchy The Domain Name System (DNS) is crucial for email delivery, acting as the internet’s phone book that translates domain names to IP addresses.\nDomain Hierarchy (read right to left): Root Domain: The invisible “.” at the end of all domains TLDs (Top-Level Domains): .com, .org, .net, etc. ccTLDs (Country Code TLDs): .ca (Canada), .uk (United Kingdom), etc. Second-Level Domains: example.co, example.ca, example.com Subdomains: mail.example.co, support.example.co When you control a domain like example.co, you can create subdomains and set DNS records that affect email delivery and authentication.\nDNS Records for Email: MX Records: Specify which mail servers accept email for your domain and their priority.\nexample.co. 3600 IN MX 10 aspmx.l.google.com.\rTXT Records: Store SPF, DKIM, and DMARC policies as text.\nexample.co. 3600 IN TXT \u0026#34;v=spf1 include:_spf.google.com ~all\u0026#34;\rA/AAAA Records: Map hostnames to IP addresses (IPv4/IPv6).\nmail.example.co. 3600 IN A 192.168.1.1\rPTR Records: Reverse DNS lookup (IP to hostname).\n1.1.168.192.in-addr.arpa. PTR mail.example.co.\rThese records work together to ensure proper email routing and authentication.\nDNS and SPF Example for Multiple Domains: For organizations with multiple domains, each domain needs its own DNS records:\nFor main domain with Google Workspace:\nexample.co TXT \u0026#34;v=spf1 …","date":1743984000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744074974,"objectID":"9494f508fd078f4bb420ac68a7135d83","permalink":"https://antoine.weill-duflos.fr/en/post/emails/","publishdate":"2025-04-07T00:00:00Z","relpermalink":"/en/post/emails/","section":"post","summary":"A comprehensive guide to email delivery concepts, including SMTP protocol, authentication methods, DNS configuration, and best practices for managing multiple domains.","tags":["email","SMTP","SPF","DKIM","DMARC","DNS"],"title":"Understanding Email Delivery: A Comprehensive Guide","type":"post"},{"authors":["Chantal Hutchison","Joseph Hewlett","Siamak Arbatani","Antoine Weill-Duflos","Jozsef Kovecses"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"02c01b20c7c673408a0d1e46fa5404ed","permalink":"https://antoine.weill-duflos.fr/en/publication/hutchison-haptic-2024/","publishdate":"2024-01-27T19:18:16.792249Z","relpermalink":"/en/publication/hutchison-haptic-2024/","section":"publication","summary":"Model-Mediated Teleoperation (MMT) between a haptic device and a remote or virtual environment uses a local model of the environment to compensate for latency of communication. MMT is often case-specific, and requires underlying latency distributions to be known. We propose a novel approach – which we refer to as the DelayRIM – which uses the timestepping aspect of a Reduced Interface Model for the virtual environment to render an up-to-date force to the haptic device from the delayed information. RIM is applicable to any physical system, and the DelayRIM itself makes no underlying assumption about the latency distribution. We show that for realistic variable delays, the DelayRIM improves transparency compared to other methods.","tags":["Delays","Force","Haptic interfaces","Haptics","Jacobian matrices","Mathematical models","Model-mediated teleoperation","Multi-user study","Predictive models","Reduced interface model","Variable time delay","Virtual environments"],"title":"Haptic Interactions Subject to Variable Latency","type":"publication"},{"authors":[],"categories":[],"content":"","date":1704048919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706392733,"objectID":"f0d3686e6debaa112c6cb9cd1a1c205e","permalink":"https://antoine.weill-duflos.fr/en/project/2diy/","publishdate":"2023-12-31T14:55:19-04:00","relpermalink":"/en/project/2diy/","section":"project","summary":"The Haply 2diy is an affordable plannar haptic device with great force feedback performances.","tags":["haptic"],"title":"Haply 2diy","type":"project"},{"authors":["Antoine Weill-Duflos","Maciej Lacki","Colin GALLACHER"],"categories":null,"content":"","date":1698796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"6e8e4bfe3bbd042cd1f44c3e133ca65e","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-haptic-2023/","publishdate":"2024-01-27T19:18:16.815312Z","relpermalink":"/en/publication/weill-duflos-haptic-2023/","section":"publication","summary":"","tags":["Braking device","Coupled","Haptic","Housing","Transmission"],"title":"Haptic Braking Device and Parallel Hybrid Actuator System Using Same","type":"publication"},{"authors":["Colin GALLACHER","Felix DESOURDY","Oliver Philbin-Briscoe","Antoine Weill-Duflos","Maciej Lacki","Nicholas Ong","Jessica Henry","Yi Ding"],"categories":null,"content":"","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"c8ed5b67746bf97b971fa445a1e58bb1","permalink":"https://antoine.weill-duflos.fr/en/publication/gallacher-apparatus-2023/","publishdate":"2024-01-27T19:18:16.785238Z","relpermalink":"/en/publication/gallacher-apparatus-2023/","section":"publication","summary":"","tags":["Exemplary","Link","Linkage","Relative","Tool"],"title":"Apparatus and Method for Tracking Motion and Providing Haptic Feedback","type":"publication"},{"authors":["Felix DESOURDY","Dylan SAWATZKY","Antoine Weill-Duflos"],"categories":null,"content":"","date":1693526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"feb9102e7640a7c82e91d135daa57550","permalink":"https://antoine.weill-duflos.fr/en/publication/desourdy-capstan-2023/","publishdate":"2024-01-27T19:18:16.771226Z","relpermalink":"/en/publication/desourdy-capstan-2023/","section":"publication","summary":"","tags":["Along","Cable","Force","Jamming","Tension"],"title":"Capstan Drive Transmission Self-Tensioning Apparatus and Method","type":"publication"},{"authors":["Maurício Fontana de Vargas","David Marino","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":null,"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"bd30cd98db9826f2f6f3f739dd37bd0e","permalink":"https://antoine.weill-duflos.fr/en/publication/vargas-training-2023/","publishdate":"2024-01-27T19:18:16.800299Z","relpermalink":"/en/publication/vargas-training-2023/","section":"publication","summary":"The ability to understand simple vocabulary, conveyed by haptics, has demonstrated encouraging results, even with limited training. However, the level of achievable accuracy on communication indicative of real-world conversations, typically characterized by long phrases formed by complex vocabulary, remains unknown. This work presents an in-depth case-study analysis of the learning path of one experienced participant over a two-month period of daily practice with our vibrotactile communication apparatus. By the end of the two months, this participant was able to correctly identify 97% of the words in phrases consisting of 6-8 words, delivered as a sequence of vibration patterns. To the best of our knowledge, this work demonstrates the most advanced haptic rendering of language through a wearable device to date.","tags":["Haptic interfaces","Human computer interaction","Natural languages","Oral communication","Sociology","Speech processing","Statistical analysis","Training","Vibrations","Vocabulary","Wearable computers","Wearable computers"],"title":"Training to Understand Complex Haptic Phrases: A Longitudinal Investigation","type":"publication"},{"authors":["Jeremy Cooperstock","Antoine Weill-Duflos","Juliette REGIMBAL","Nusaiba RADI","Jeffrey Blum","Parisa ALIREZAEE","Yukai Zhang"],"categories":null,"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"36184ff72e5b4688f2c60bf5a18f75dd","permalink":"https://antoine.weill-duflos.fr/en/publication/cooperstock-methods-2023/","publishdate":"2024-01-27T19:18:16.754211Z","relpermalink":"/en/publication/cooperstock-methods-2023/","section":"publication","summary":"Methods and systems for controlling a haptic display are provided. Data associated with first and second data types is obtained, the data defining values for the first and second data types. The first and second data types are associated to first and second vibration features of the haptic display, respectively, the second vibration feature different from the first vibration feature. A vibration pattern comprising a plurality of vibration pulses representing the first and second vibration features within a common time interval is produced on the haptic display, wherein the first vibration feature is expressed based on the values of the data for the first data type and the second vibration feature is expressed based on the values of the data for the second data type.","tags":["Data","Feature","Pulses","Values","Vibration"],"title":"Methods and Systems for Controlling a Haptic Display","type":"publication"},{"authors":[],"categories":null,"content":"","date":1685207123,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685216681,"objectID":"8aed05b45e7a999ba1ce0368759037a6","permalink":"https://antoine.weill-duflos.fr/en/event/srl_25year/","publishdate":"2020-05-27T15:05:23+01:00","relpermalink":"/en/event/srl_25year/","section":"event","summary":"","tags":["haptics"],"title":"Shared Reality Lab 25th Anniversary","type":"event"},{"authors":["Antoine Weill--Duflos"],"categories":[],"content":"Antoine Weill–Duflos Shared Reality Lab 25-Year Anniversary\n2023-05-27\nWhat did I do ? In Short Wearable haptic devices Mixing Voice and Haptic effects Vibrotactile signals for ER/ICU Haptic Phonemes A memorable anecdote How long does it take to get a Raspberry Pi hacked ? “But there’s no firewall ?\n-No, every machine get its own IP address on the internet”\nWhat I do now Head of R\u0026amp;D\u0026amp;I at Haply\n(and also the IT guy, because now I now how long it takes to get a Raspberry Pi hacked) In Short Thank you ","date":1685196323,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685216681,"objectID":"8eaa319662c3a27f24c8c4f57a28a869","permalink":"https://antoine.weill-duflos.fr/en/slides/srl25/","publishdate":"2023-05-27T15:05:23+01:00","relpermalink":"/en/slides/srl25/","section":"slides","summary":"Presentation of Antoine Weill--Duflos","tags":[],"title":"Shared Reality Lab 25-Year Anniversary","type":"slides"},{"authors":["Jeremy R. Cooperstock","Pascal E. Fortin","Jeffrey R. Blum","Antoine Weill-Duflos"],"categories":null,"content":"","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"cf65beb998c70c2092b68db43101d59d","permalink":"https://antoine.weill-duflos.fr/en/publication/cooperstock-system-2023/","publishdate":"2024-01-27T19:18:16.76422Z","relpermalink":"/en/publication/cooperstock-system-2023/","section":"publication","summary":"","tags":["Body part","Contact force","Physiological","User","Wearable device"],"title":"System and Method for Wearable Device Contact Force Estimation and Adjustment Feedback","type":"publication"},{"authors":["Colin GALLACHER","Felix DESOURDY","Oliver PHILBIN-BRISCOE","Antoine Weill-Duflos","Maciej LACKI","Nicholas Ong","Jessica HENRY","Yi Ding"],"categories":[],"content":"","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"b38a5d095c50f5217017a4b49f7b66b7","permalink":"https://antoine.weill-duflos.fr/en/publication/gallacher-apparatus-2022/","publishdate":"2022-08-02T13:36:35.969785Z","relpermalink":"/en/publication/gallacher-apparatus-2022/","section":"publication","summary":"","tags":["Exemplary","Link","Linkage","Relative","Tool"],"title":"Apparatus and Method for Tracking Motion and Providing Haptic Feedback","type":"publication"},{"authors":["Mauricio Fontana de Vargas","David Marino","Antoine Weill-Duflos","Jeremy Cooperstock"],"categories":[],"content":"","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"bb6107468fc8a71811ccc53ae5d40374","permalink":"https://antoine.weill-duflos.fr/en/publication/fontana-de-vargas-pushing-2022/","publishdate":"2022-08-12T13:20:48.181182Z","relpermalink":"/en/publication/fontana-de-vargas-pushing-2022/","section":"publication","summary":"The ability to understand simple vocabulary, conveyed by haptics, has demonstrated encouraging results, even with limited training. However, the level of achievable accuracy on communication indicative of real-world conversations, typically characterized by long phrases formed by complex vocabulary, remains unknown. This work presents an in-depth quantitative and qualitative analysis of the learning path of one experienced participant over a two-month period of daily practice with our vibrotactile communication system. By the end of the two months, this participant was able to correctly identify 97% of the words in phrases consisting of 6-8 words, delivered as a sequence of vibration patterns. We compare the progress of this individual with three naive participants who practiced on single-word identification, discussing the subjective aspects of haptic communication, such as the cognitive process of decoding words, and the need for personalization, both in the training program and the haptic encoding.","tags":["Haptics","Multimodal communication","Phoneme","Tactile aid"],"title":"Pushing the Boundaries of Vibrotactile Communication: Training to Understand Complex Phrases","type":"publication"},{"authors":["Jeremy Cooperstock","Antoine Weill-Duflos","Juliette REGIMBAL","Nusaiba RADI","Jeffrey BLUM","Parisa ALIREZAEE","Yukai Zhang"],"categories":[],"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"57efc5dccd888ffd4b13486629eb5191","permalink":"https://antoine.weill-duflos.fr/en/publication/cooperstock-methods-2021/","publishdate":"2022-08-02T13:36:24.288997Z","relpermalink":"/en/publication/cooperstock-methods-2021/","section":"publication","summary":"","tags":["Data","Feature","Pulses","Values","Vibration"],"title":"Methods and Systems for Controlling a Haptic Display","type":"publication"},{"authors":["Karon E MacLean","Oliver Schneider","Antoine Weill-Duflos","Vincent Levesque","Pourang Irani","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"67dfbf764816840c3b9f135ee1fd1c6e","permalink":"https://antoine.weill-duflos.fr/en/publication/maclean-canhap-2021/","publishdate":"2021-09-01T18:15:09.942393Z","relpermalink":"/en/publication/maclean-canhap-2021/","section":"publication","summary":"We describe the graduate-level CanHap 501 (wiki.canhaptics.ca) course, an introduction to the inception, creation and evaluation of haptic and multimodal human-computer interfaces. The course covers perceptual and attentional foundations, and emphasizes control and/or display of computed sensations and environments through haptic devices to users' sense of touch for the purpose of haptic communication— e.g., signalling, social and affective touch, and sharing of control between humans and smart systems.","tags":["\"Conferences\"","\"Haptic interfaces\"","\"Human computer interaction\""],"title":"CanHap 501: Learning Haptic UX Design in Remote Teams","type":"publication"},{"authors":["Emilie Waite","Thomas M. Fitz-Gerald","Abdel-Rahman Sadaqa","Huaijin Shi","Pascal E. Fortin","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"db0dddb8f55872f4e1a592ba7a7cbaed","permalink":"https://antoine.weill-duflos.fr/en/publication/waite-3-d-2021/","publishdate":"2024-01-27T19:18:16.807806Z","relpermalink":"/en/publication/waite-3-d-2021/","section":"publication","summary":"","tags":null,"title":"3D Printed Tactile Illusions and Demonstrations","type":"publication"},{"authors":["Marc Demers","Pascal E. Fortin","Antoine Weill-Duflos","Yongjae Yoo","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"80f6b64bd17e1ff0c45196af5ad252ed","permalink":"https://antoine.weill-duflos.fr/en/publication/demers-active-2021/","publishdate":"2021-09-01T18:15:09.263778Z","relpermalink":"/en/publication/demers-active-2021/","section":"publication","summary":"","tags":[],"title":"Active Sampling for Efficient Subjective Evaluation of Tactons at Scale","type":"publication"},{"authors":["Yaxuan Li","Yongjae Yoo","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"7ea5303b952e915e9c4c0ca487143503","permalink":"https://antoine.weill-duflos.fr/en/publication/li-context-aware-2021/","publishdate":"2021-09-01T18:10:31.710016Z","relpermalink":"/en/publication/li-context-aware-2021/","section":"publication","summary":"","tags":[],"title":"Context-Aware Automatic Haptic Effect Generation Algorithm for Improved Content Viewing Experiences","type":"publication"},{"authors":["David Marino","Maurício Fontana de Vargas","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"3d47a11c17c380fc592ac3878ed5e9ab","permalink":"https://antoine.weill-duflos.fr/en/publication/marino-conversing-2021/","publishdate":"2021-09-01T18:15:10.605496Z","relpermalink":"/en/publication/marino-conversing-2021/","section":"publication","summary":"","tags":[],"title":"Conversing Using WhatsHap: A Phoneme Based Vibrotactile Messaging Platform","type":"publication"},{"authors":["Antoine Weill-Duflos","Nicholas Ong","Felix Desourdy","Benjamin Delbos","Steve Ding","Colin Gallacher"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"c8d59f1cd1f586010c09dc7a88d89a82","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-haply-2021/","publishdate":"2022-08-02T13:36:42.500796Z","relpermalink":"/en/publication/weill-duflos-haply-2021/","section":"publication","summary":"","tags":[],"title":"Haply 2diy: An Accessible Haptic Platform Suitable for Remote Learning","type":"publication"},{"authors":["Mauricio Fontana de Vargas","David Marino","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"e386a288ad32df20f807cf19400a2a10","permalink":"https://antoine.weill-duflos.fr/en/publication/de-vargas-speaking-2021/","publishdate":"2021-07-23T20:27:27.18256Z","relpermalink":"/en/publication/de-vargas-speaking-2021/","section":"publication","summary":"","tags":[],"title":"Speaking Haptically: From Phonemes to Phrases with a Mobile Haptic Communication System","type":"publication"},{"authors":["Yaxuan Li","Yongjae Yoo","Antoine Weill-Duflos","Jeremy Cooperstock"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"47b17f7ccc2a1b183d5bb46a32109a4b","permalink":"https://antoine.weill-duflos.fr/en/publication/li-towards-2021/","publishdate":"2022-08-02T13:36:39.457683Z","relpermalink":"/en/publication/li-towards-2021/","section":"publication","summary":"","tags":[],"title":"Towards Context-aware Automatic Haptic Effect Generation for Home Theatre Environments","type":"publication"},{"authors":[],"categories":null,"content":"","date":1598018400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"016d41d4a644044d33bf351394693f9d","permalink":"https://antoine.weill-duflos.fr/en/event/haid2020/","publishdate":"2020-08-24T10:46:50-04:00","relpermalink":"/en/event/haid2020/","section":"event","summary":"","tags":["haptics"],"title":"Haptic Augmentation of Audio and its Effects on Speech Perception","type":"event"},{"authors":[],"categories":null,"content":"","date":1595772000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"1a6f0d9725c45a9ab78b18084db9c225","permalink":"https://antoine.weill-duflos.fr/en/event/montreal_haptic/","publishdate":"2020-06-11T11:46:50-04:00","relpermalink":"/en/event/montreal_haptic/","section":"event","summary":"","tags":["haptics"],"title":"Projects Overview, Montréal Haptics HUB","type":"event"},{"authors":[],"categories":[],"content":"","date":1591896776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596038349,"objectID":"fa9cb1e5ceba256579f3eaa028c60bf2","permalink":"https://antoine.weill-duflos.fr/en/project/broadcasting-haptic/","publishdate":"2020-06-11T13:32:56-04:00","relpermalink":"/en/project/broadcasting-haptic/","section":"project","summary":"I investigate solutions to facilitate the authoring and demonstration of haptic effect in remote situations.","tags":["haptics","teleoperation"],"title":"Broadcasting Haptic","type":"project"},{"authors":[],"categories":[],"content":" Evidence of Sensory Adaptation to Kinaesthetic Sensations in the Human Somatosensory System A. Weill–Duflos, S. Sakr, S. Haliyo, S. Régnier McGill University/Sorbonne University\nSensory/Neural Adaptation gradual decrease over time in the responsiveness of the sensory system to a constant stimulus.\n$~$\n$~$\n$~$\n$~$\n$~$\n$$ $$\nSensory/Neural Adaptation gradual decrease over time in the responsiveness of the sensory system to a constant stimulus.\nDoes Sensory Adaptation exist for force feedback? Yes for vibrotactile\nDoes Sensory Adaptation exist for force feedback? Method Press “space” when a diminishing force is felt.\nMethod Press “space” when a diminishing force is felt.\nStimulus $Torque(t)=A\\exp\\left(\\frac{-(t-b)}{\\tau}\\right)$\nMow, do you think we have the same tactile sensitivity everywhere\n2dp 1mm in the tongue\n3 to 8 on the finger\n36 to 75mm on the back\nIt’s optimisation of the ressources, we don’t need more informations from the back, but we use our hand to grab stuff.\nWhy optimise\nParticipants 58 Participants (40M and 18W)\nMean age of 29y, [18,73]\nResults Conclusion Evidence of adaptation Improve design of haptic device Energy saving I bet you’ve all seen an optical illusion before.\nHere it’s circle that looks like a spiral.\nThank you! ","date":1583712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"cb328165c9d723e90adcf31982111b0b","permalink":"https://antoine.weill-duflos.fr/en/slides/adaptation/","publishdate":"2020-03-09T00:00:00Z","relpermalink":"/en/slides/adaptation/","section":"slides","summary":"An introduction to Kinaesthetic Adaptation.","tags":[],"title":"Adaptation","type":"slides"},{"authors":[],"categories":[],"content":" Haptic Augmentation of Audio and its Effects on Speech Perception A. Weill–Duflos, P. Fortin, F. Al Taha, J. R. Cooperstock Context Voice characteristics influence perception of speaker’s professional abilities\nVoice pitch is one of the factor\nCan we influence it with vibrotactile feedback ? Setup Chair with 100W tactile loudspeaker TTS voices from Google Wavenet models Experiment I urge you to vote for me this November\npair of voices - chose the “competent”/“stronger”/“trustworthy” - low/high pitch with/without haptic M/F Results Choice of high-pitched voices: Conclusion did not replicate previous findings - strength is reinforced Thank you! ","date":1583712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"e4d3c2e0fad4c4d28763d8459350f4ea","permalink":"https://antoine.weill-duflos.fr/en/slides/bwhaid2020/","publishdate":"2020-03-09T00:00:00Z","relpermalink":"/en/slides/bwhaid2020/","section":"slides","summary":"Haptic Augmentation of Audio and its Effects on Speech Perception","tags":[],"title":"BarryWhaptics HAID","type":"slides"},{"authors":["Pascal E. Fortin","Jeffrey R. Blum","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"036bad4f5280cb30c29a9777eb5df9ee","permalink":"https://antoine.weill-duflos.fr/en/publication/fortin-contact-2020/","publishdate":"2021-07-23T20:27:31.240891Z","relpermalink":"/en/publication/fortin-contact-2020/","section":"publication","summary":"","tags":[],"title":"Contact Force Estimation from Raw Photoplethysmogram Signal","type":"publication"},{"authors":["Jonathan Cailliez","Antoine Weill-Duflos","Mokrane Boudaoud","Stéphane Régnier","Sinan Haliyo"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"1a59a2d76c434fb9676668d78d489935","permalink":"https://antoine.weill-duflos.fr/en/publication/cailliez-design-2020/","publishdate":"2021-07-23T20:27:25.29368Z","relpermalink":"/en/publication/cailliez-design-2020/","section":"publication","summary":"","tags":[],"title":"Design and Control of a Large-Range Nil-Stiffness Electro-Magnetic Active Force Sensor","type":"publication"},{"authors":["Ahmed Farooq","Hong Z. Tan","Antoine Weill-Duflos","Jeremy R. Cooperstock","Roope Raisamo"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"15739e8795bdbc39ef0b924f9d03d5de","permalink":"https://antoine.weill-duflos.fr/en/publication/farooq-embedded-2020/","publishdate":"2021-07-23T20:27:29.126409Z","relpermalink":"/en/publication/farooq-embedded-2020/","section":"publication","summary":"","tags":[],"title":"Embedded Haptic Waveguides to Improve Tactile Feedback: Designing a Custom 3D-Printed Surface to Enhance Signal Mediation","type":"publication"},{"authors":["Antoine Weill-Duflos","Sophia Sakr","Sinan Haliyo","Stéphane Régnier"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"9e6f89915725bbad840cc128e130db67","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-evidence-2020/","publishdate":"2020-06-11T15:25:30.702751Z","relpermalink":"/en/publication/weill-duflos-evidence-2020/","section":"publication","summary":"Sensory adaptation is a phenomenon well known for most of the senses and may be a way to optimize the encoding of sensory signals for the finite processing resources of the neural system. The occurrences are documented in the case of hearing, smell, taste, sight, and certain modalities of the sense of touch. For example, it is well known that our eyes adjust between darker and brighter environments. We are specifically interested in the case of sensory adaptation in the kinaesthetic system and the way it applies to forces. We make the hypothesis of the existence of kinaesthetic sensory adaptation. The specific hypothesis is that instead of knowing the absolute magnitude of a force we are sensitive to changes. To determine the existence of sensory adaptation to forces as well as its properties we led a pilot and two experiments. The experiments involved 58 participants, 48 participant's results were analyzed. From the results, we were able to find the proof of a form of sensory adaptation to kinaesthetic feedback. This phenomenon can be seen as a high-pass filter with a time constant of 14 s. These findings can find application in algorithms to reduce the energy needed for force feedback devices by slowly decreasing the force, similarly to the wash-out filter in motion simulators.","tags":["haptics"],"title":"Evidence of Sensory Adaptation to Kinaesthetic Sensations in the Human Somatosensory System","type":"publication"},{"authors":["Parisa Alirezaee","Antoine Weill-Duflos","Joseph J. Schlesinger","Jeremy R. Cooperstock"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"d8aec531d726a5433fa518bced629d24","permalink":"https://antoine.weill-duflos.fr/en/publication/alirezaee-exploring-2020/","publishdate":"2020-06-11T15:25:30.674752Z","relpermalink":"/en/publication/alirezaee-exploring-2020/","section":"publication","summary":"Noise in critical care units, in particular, from patient monitor alarms, is harmful for clinicians and patients alike. This has motivated research aimed at shifting the delivery of physiological vital sign information and annunciation of alarm events from visual and auditory devices to haptic transducers. We compare performance in perceiving and identifying the specific type and level of a vital sign that has entered a high or low state, i.e., an alarm event, using several designs of a vibrotactile display, against that of the traditional auditory alarm in conjunction with a graphical patient monitor. A distractor activity was used to simulate competing task demands in the clinical environment. Responses were assessed with respect to response time and accuracy. With sufficient anatomical separation of the actuators, certain vibrotactile information rendering strategies demonstrated performance that was not significantly different from that of the baseline condition, both in response time and accuracy. We conclude that vibrotactile delivery of patient vitals can support alarm-state vital sign identification competitive with graphical and auditory alarm display conditions, without significantly impacting performance on a parallel attention-demanding activity. This suggests the possibility of improving high-impact healthcare environments by replacing disturbing auditory alarms with vibrotactile information delivery to clinicians.","tags":["haptics"],"title":"Exploring the Effectiveness of Haptic Alarm Displays for Critical Care Environments","type":"publication"},{"authors":["Antoine Weill-Duflos","Pascal E. Fortin","Feras Al Taha","Jeremy R. Cooperstock"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"f99a4ecf5560cd51f9507470fa0af9d0","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-haptic-2020/","publishdate":"2020-07-29T15:34:38.897452Z","relpermalink":"/en/publication/weill-duflos-haptic-2020/","section":"publication","summary":"Voice characteristics are known to influence people's perception of a speaker's professional abilities, often offering an unfair disadvantage to speakers in position of perceived vulnerability. By using a custom speech to haptics synthesis framework, this paper presents results from a user study investigating the influence of haptic speech enhancement on speaker's characteristic perception. A custom speech to haptic system is used to first replicate a study from Klofstad et al. examining how voice pitch influences perception of speaker strength, competence and trustworthiness, and second to explore the impact of multimodal stimulus presentation on these perceived characteristics. Our preliminary findings suggest that the perceived strength of a speaker with a higher voice pitch is enhanced, whereas the outcome is uncertain for competence. Perceived trustworthiness was not affected by the system at all. This work puts forward the potential positive effect that the use of haptic-enhanced communication system could have in social and professional communications, but also outlines its limitations.","tags":null,"title":"Haptic Augmentation of Audio and Its Effects on Speech Perception","type":"publication"},{"authors":["Juliette Regimbal","Nusaiba Radi","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"c715ba0f8b108dbb052436d938c48999","permalink":"https://antoine.weill-duflos.fr/en/publication/regimbal-single-actuator-2020/","publishdate":"2021-07-23T20:27:33.337362Z","relpermalink":"/en/publication/regimbal-single-actuator-2020/","section":"publication","summary":"","tags":[],"title":"Single-Actuator Simultaneous Haptic Rendering for Multiple Vital Signs","type":"publication"},{"authors":["Preeti Vyas","Feras Al Taha","Jeffrey R. Blum","Antoine Weill-Duflos","Jeremy R. Cooperstock"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"922aa9e5328bafd6adc612749ab1e680","permalink":"https://antoine.weill-duflos.fr/en/publication/vyas-ten-2020/","publishdate":"2020-06-11T15:25:30.696751Z","relpermalink":"/en/publication/vyas-ten-2020/","section":"publication","summary":"In comparison with fingers, toes are relatively unexplored candidates for multi-site haptic rendering. This is likely due to their reported susceptibility to erroneous perception of haptic stimuli, owing to their anatomical structure. We hypothesize that this shortcoming can be mitigated by careful design of the tactile encoding to account for the idiosyncrasies of toe perception. Our efforts to design such an encoding achieved an improved perceptual accuracy of 18% for poking and 16% for vibrotactile stimuli. As we demonstrate, in this article, the resulting perceptual accuracy achieved by the proposed tactile encoding approaches that of the fingers, allowing for consideration of the toes as a practical location to render multi-site haptic stimuli.","tags":["haptics"],"title":"Ten Little Fingers, Ten Little Toes: Can Toes Match Fingers for Haptic Discrimination?","type":"publication"},{"authors":[],"categories":null,"content":"","date":1572536810,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"3feed1bba88e76c86312f771f2c63f85","permalink":"https://antoine.weill-duflos.fr/en/event/hci_haptic/","publishdate":"2020-06-11T11:46:50-04:00","relpermalink":"/en/event/hci_haptic/","section":"event","summary":"","tags":["haptics"],"title":"Haptics introduction, HCI class (ECSE 424/542)","type":"event"},{"authors":[],"categories":[],"content":"Designing haptic interactions We often underestimate how important the sense of touch is in our daily interactions.\nIt’s the first sense baby develops.\nIf you think about the other senses, they are very localized, but touched is all around !\nA bit of Taxonomy Somatosensory systems\nSomesthetic senses:\nsense of touch proprioception haptic perception Haptic feedback - Kinesthetic - Tactile When we say «touch» we may actually refer to different things, is the pain felt the same way as cold ? Do we feel force with the same mechanisms as we feel the softness of a blanket ?\nLet’s talk about how everything works, but first let’s introduce some words.\nThe somatosensory system is a part of the sensory nervous system, it responds to changes at the surface or inside of the body.\nThe somatic senses or somesthetic senses are the sense of touch, proprioception (sense of position and movement) and haptic perception. Haptic perception is often associated with active touch.\nAnd because that’s not enough term, engineer often talks about Haptic feedback being divided in kinesthetic and tactile.\nStill following ? lets try to get into how it works.\nTypes of tactile receptors Mechanoreceptors Thermoreceptors Nociceptors All sharing the same channel Gate Control Theory running cool water on a burned area = less pain Tactile receptors are cells reacting to tactile stimilus, they can be divide in thre types.\nInterestingly they sort of use the same channel to convey the information to the brain.\nThis create an effect called gating, information are competing to get to the brain.\nAnd that’s a why running your finger under cool water diminish the pain sensation associated with a burn.\nTactile receptors Jets give a closer look a tactile receptors.\nRuffini corpuscle are sensing skin stretch.\nMeissner respond to light touch and virbation around 50Hz Pacinain corpuscle will detect rapid 200-300Hz vibration\nMerkel disc detect pressure.\nTwo-point discrimination Do we have the same tactile sensitivity everywhere?\nMow, do you think we have the same tactile sensitivity everywhere\n2dp 1mm in the tongue\n3 to 8 on the finger\n36 to 75mm on the back\nIt’s optimisation of the ressources, we don’t need more informations from the back, but we use our hand to grab stuff.\nWhy optimise\nCortical Homunculus Because we don’t have infinite ressources\nThis is a sensory homunculus, it shows the parts of the brain that are processing tactile input from specific inputs of the body.\nDoes someone have a guess on what would happends if I loose a finger, or an hand ?\nPlaying with the senses Now that we covered how it’s working, let’s try to find how to break it.\nBy that I mean, can we send signals that will create a confusing sensation.\nOptical illusions I bet you’ve all seen an optical illusion before.\nHere it’s circle that looks like a spiral.\nAuditory illusions Auditory illusions\nAuditory illusions are less known but I think you may know about the Yanny or Laurel one. Haptic illusions cross your finger and touch your nose cutaneous rabbit illusion Haptic illusion are less known, Prof. Vincent Hayward, former McGill professor, gives a nice explaination for that in a talk I’m attaching in the end of this presentation. The issue with haptic illusion is that they tend involve mechanical apparatus.\nStill, I listed two exemple that only requires your hands.\nAnd I’ve also been doing a project on making tactile illusions more accessible by taking advantage of the democratization of 3D printing.\nHaptic communication Tactile feedback Vibrotactile feedback Thermal feedback Force feedback I think that was already a big explaination of the senses, now let’s take a look at the design aspect.\nHaptic communication is divided into 4 cat.\nSome realisations I will give you two exemple of haptic device and I’d like you to think about what type of category are involved. Surface Interaction MIT Tangible Media Group\nHaptic teleoperation This second exemple is a nice reminder of why we need haptic feedback. Vibrotactile actuators The exemple where not that much about vibrotactile feedback. Vibrotactile feedback is probably the type of haptic communication you are the more familiar with, because of smartphones or video game console.\nVibrotactile is achieved using a vibrotactile actuators. They can be divided in 3cat.\nMore vibrotactile actuators Taptic engive or high-end haptic devices are actually just carrefully tuned lras. Try it on your phone ! Using html5 API\nRecent work Online ressources Talks A sense of Truth, interview of V. Hayward\nThe technology of touch, K. Kuchenbecker TED talk\nOnline tools Haptipedia: online database of haptic devices\nVibViz: explore vibrations patterns\nQuestions? ","date":1572393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"43b424164723bbd091d1a5fb50463511","permalink":"https://antoine.weill-duflos.fr/en/slides/haptic/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/en/slides/haptic/","section":"slides","summary":"An introduction to Haptic.","tags":[],"title":"Haptic","type":"slides"},{"authors":[],"categories":[],"content":"Sharing haptic and haptic in shared spaces We often underestimate how important the sense of touch is in our daily interactions.\nIt’s the first sense baby develops.\nIf you think about the other senses, they are very localized, but touched is all around !\n3D printed illusions Teaching/Sharing experience Vibroadcast Transmitting haptic signals accross devices BarryWhaptics Enhancing voice with haptic Shoes for XR Floor experiences: Vibrations Hot/Cold/Pain ","date":1572393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660311494,"objectID":"d53ec81aed44dd43462a5f95ded2a675","permalink":"https://antoine.weill-duflos.fr/en/slides/montrealhaptic2020/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/en/slides/montrealhaptic2020/","section":"slides","summary":"Montréal Haptics 2020 presentation","tags":[],"title":"Sharing haptic and haptic in shared spaces","type":"slides"},{"authors":[],"categories":[],"content":"","date":1570906519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"d8354f1b3e80815d6b231c52b623d6bc","permalink":"https://antoine.weill-duflos.fr/en/project/3dprintedillusions/","publishdate":"2019-10-12T14:55:19-04:00","relpermalink":"/en/project/3dprintedillusions/","section":"project","summary":"We propose a series of haptic illusions and demonstrations that can be fabricated using any FDM 3D printer. Once printed, they can be fully assembled by hand.","tags":["haptic"],"title":"3D printed haptic illusions","type":"project"},{"authors":[],"categories":[],"content":"At present, the operating room (OR) and intensive care unit (ICU) are noisy environments, exacerbated by frequent alarms. Regardless of whether the alarms are valid or false, all command attention, raise stress, and are often irrelevant to the responsibilities of individual clinicians. To cope with these problems, we are investigating the possibility of using audio only for those alarms that should be announced to the entire team, but delivering other alarm cues individually, through haptics vibrations.\n","date":1570906511,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"eff362acc3080d50f8fcd261b7a2fb6b","permalink":"https://antoine.weill-duflos.fr/en/project/hapticicu/","publishdate":"2019-10-12T14:55:11-04:00","relpermalink":"/en/project/hapticicu/","section":"project","summary":"At present, the operating room (OR) and intensive care unit (ICU) are noisy environments, exacerbated by frequent alarms. Regardless of whether the alarms are valid or false, all command attention, raise stress, and are often irrelevant to the responsibilities of individual clinicians. To cope with these problems, we are investigating the possibility of using audio only for those alarms that should be announced to the entire team, but delivering other alarm cues individually, through haptics vibrations.\n","tags":["haptic","medical"],"title":"Haptic for OR/ICU","type":"project"},{"authors":[],"categories":[],"content":"Nerve damage, frequently caused by injury, can result in the loss of sensorimotor functions in certain parts of the hand. After suturing the nerve, unpleasant sensations on contact, including tingling and electric shocks are often felt. Following nerve regrowth, it is necessary to re-train the brain to interpret the signals from these nerves correctly. This project involves the design of haptic devices to help in this process of sensory reeducation, which can involve two phases, depending on the severity of the loss of sensitivity: relearning how to localize sensations, and differentiation of shapes and textures in the identification of objects.\n","date":1570906503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"d1c0f703b824dc5d7888e78cbcdbcc3d","permalink":"https://antoine.weill-duflos.fr/en/project/hapticrehab/","publishdate":"2019-10-12T14:55:03-04:00","relpermalink":"/en/project/hapticrehab/","section":"project","summary":"Nerve damage, frequently caused by injury, can result in the loss of sensorimotor functions in certain parts of the hand. After suturing the nerve, unpleasant sensations on contact, including tingling and electric shocks are often felt. Following nerve regrowth, it is necessary to re-train the brain to interpret the signals from these nerves correctly. This project involves the design of haptic devices to help in this process of sensory reeducation, which can involve two phases, depending on the severity of the loss of sensitivity: relearning how to localize sensations, and differentiation of shapes and textures in the identification of objects.\n","tags":["haptic","medical"],"title":"Haptic device for sensory reeducation","type":"project"},{"authors":[],"categories":[],"content":"","date":1570906492,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"aca97b10c29eeb68bb85b59783ff58e5","permalink":"https://antoine.weill-duflos.fr/en/project/wearablehaptics/","publishdate":"2019-10-12T14:54:52-04:00","relpermalink":"/en/project/wearablehaptics/","section":"project","summary":"","tags":["haptic"],"title":"Wearable Haptic devices","type":"project"},{"authors":[],"categories":[],"content":"The tactile sense can be used as a channel for general communication, especially in contexts where the visual and auditory modalities are occupied with other tasks or compromised. We propose a new method for communicating generic words through the sense of touch that relies on delivering vibration patterns, representing the phonemes composing the words, to the user’s skin through two vibrotactile transducers worn on the forearm. The novelty of this technique is that vibration patterns are created from the audio of the corresponding English phoneme, resulting in vibration patterns that resemble physical characteristics when uttering the phoneme during normal speech.\n","date":1570906480,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"6bf60ad74e1ccf20927531ebcb7a1c44","permalink":"https://antoine.weill-duflos.fr/en/project/hapticphonemes/","publishdate":"2019-10-12T14:54:40-04:00","relpermalink":"/en/project/hapticphonemes/","section":"project","summary":"The tactile sense can be used as a channel for general communication, especially in contexts where the visual and auditory modalities are occupied with other tasks or compromised. We propose a new method for communicating generic words through the sense of touch that relies on delivering vibration patterns, representing the phonemes composing the words, to the user’s skin through two vibrotactile transducers worn on the forearm. The novelty of this technique is that vibration patterns are created from the audio of the corresponding English phoneme, resulting in vibration patterns that resemble physical characteristics when uttering the phoneme during normal speech.\n","tags":["haptic"],"title":"HapticPhonemes","type":"project"},{"authors":[],"categories":["haptics"],"content":"","date":1570905995,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"3c4bcb871032fd01216c24943b57e954","permalink":"https://antoine.weill-duflos.fr/en/project/barrywhaptics/","publishdate":"2019-10-12T14:46:35-04:00","relpermalink":"/en/project/barrywhaptics/","section":"project","summary":"Biased perceptions of others are known to negatively influence the outcomes of social and professional interactions in many regards. This project explores how haptic effects, generated from speech, could attenuate listeners' perceived voice-related biases.","tags":["haptic"],"title":"BarryWhaptics","type":"project"},{"authors":["Jonathan Cailliez","Mokrane Boudaoud","Abdenbi Mohand-Ousaid","Antoine Weill-Duflos","Sinan Haliyo","Stéphane Régnier"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"10ad991041023ce2bd10be2acca4d632","permalink":"https://antoine.weill-duflos.fr/en/publication/cailliez-modeling-2019/","publishdate":"2019-10-29T01:20:49.797118Z","relpermalink":"/en/publication/cailliez-modeling-2019/","section":"publication","summary":"Active force sensors are based on the principle of force balancing using a feedback control. They allow, unlike passive sensors, the static characterization of forces without interference of the sensor mechanical properties on the estimated stiffness of the object to be studied. This capability is fundamental when dealing with the mechanical characterization of samples having a wide range of stiffness. This paper deals with the modeling and the experimental characterization of a new active MEMS based force sensor. This sensor includes folded-flexure type suspensions and a differential comb drive actuation allowing a linear force/voltage relationship. A control oriented electromechanical model is proposed and validated experimentally in static and dynamic operating modes using a stroboscopic measurement system. This work is a first step towards new MEMS active force sensor with high resonant frequency ($\u003e$2kHz) and high linear measurement force range (50 $μ$N). The advantage of this structure is to be able to change the sensor operating point without changing the sensor dynamics. Thus simplifying the control law. Modifying the operating point allows performing an accurate self positioning of the probe in close proximity to the surface to be studied.","tags":["Force sensor","Identification","MEMS"],"title":"Modeling and Experimental Characterization of an Active MEMS Based Force Sensor","type":"publication"},{"authors":["Antoine Weill-Duflos","Feras Al Taha","Pascal E Fortin","Jeremy R Cooperstock"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"aade456783c49405a7860e3e04109872","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-barrywhaptics-2019/","publishdate":"2019-10-29T01:20:49.798117Z","relpermalink":"/en/publication/weill-duflos-barrywhaptics-2019/","section":"publication","summary":"Studies suggest that imbalances in speaking opportunities during meetings often lead to sub-optimal meeting outcomes. These imbalances can be due to a variety of reasons, including people's perception of speakers and their voice. Indeed, speakers with higher pitched voices were shown to be perceived as having lower leadership ability. In an attempt at countering such voice-pitch related biases, this work introduces BarryWhaptics, a real-time speech-to-haptics conversion system that leverages multimodal perception to alter the listener's perception of a speaker. The system operates by augmenting human speech with vibration, applying more intense vibrations to voices that would ordinarily be considered low in dominance. Results from a pilot study assessing the influence of the system in a decision-making task demonstrate that it can meaningfully influence how users choose to follow instructions given by one speaker over another.","tags":null,"title":"BarryWhaptics: Towards Countering Social Biases Using Real-Time Haptic Enhancement of Voice","type":"publication"},{"authors":["Antoine Weill-Duflos","Feras Al Taha","Pascal E Fortin","Jeremy R Cooperstock"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"3e21cb502e1efe0be29eaec0e3fc64a9","permalink":"https://antoine.weill-duflos.fr/en/publication/weillduflos-barrywhaptics-2019/","publishdate":"2021-07-23T20:27:37.867507Z","relpermalink":"/en/publication/weillduflos-barrywhaptics-2019/","section":"publication","summary":"Studies suggest that imbalances in speaking opportunities during meetings often lead to sub-optimal meeting outcomes. These imbalances can be due to a variety of reasons, including people's perception of speakers and their voice. Indeed, speakers with higher pitched voices were shown to be perceived as having lower leadership ability. In an attempt at countering such voice-pitch related biases, this work introduces BarryWhaptics, a real-time speech-to-haptics conversion system that leverages multimodal perception to alter the listener's perception of a speaker. The system operates by augmenting human speech with vibration, applying more intense vibrations to voices that would ordinarily be considered low in dominance. Results from a pilot study assessing the influence of the system in a decision-making task demonstrate that it can meaningfully influence how users choose to follow instructions given by one speaker over another.","tags":[],"title":"BarryWhaptics: Towards Countering Social Biases Using Real-Time Haptic Enhancement of Voice","type":"publication"},{"authors":["Jeffrey R Blum","Pascal E Fortin","Feras Al Taha","Parisa Alirezaee","Marc Demers","Antoine Weill-Duflos","Jeremy R Cooperstock"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"fe88903d1699e084b33e37b04d987dfe","permalink":"https://antoine.weill-duflos.fr/en/publication/blum-getting-2019/","publishdate":"2019-10-29T01:20:49.795119Z","relpermalink":"/en/publication/blum-getting-2019/","section":"publication","summary":"As haptics have become an ingrained part of our wearable experience, particularly through phones, smartwatches and fitness trackers, significant research effort has been conducted to find new ways of using wearable haptics to convey information, especially while we are on-the-go. In this article, instead of focusing on aspects of haptic information design, such as tacton encoding methods, actuators, and technical fabrication of devices, we address the more general recurring issues and \"gotchas\" that arise when moving from core haptic perceptual studies and in-lab wearable experiments to real world testing of wearable vibrotactile haptic systems. We summarize key issues for practitioners to take into account when designing and carrying out in-the-wild wearable haptic user studies, as well as for user studies in a lab environment that seek to simulate real-world conditions. We include not only examples from published work and commercial sources, but also hard-won illustrative examples derived from issues and failures from our own haptic studies. By providing a broad-based, accessible overview of recurring issues, we expect that both novice and experienced haptic researchers will find suggestions that will improve their own mobile wearable haptic studies.","tags":["Actuators","Haptic interfaces","vibrotactile","Skin","Vibrations","Wearable haptics","haptic assessment","Hardware","in-the-wild studies","Special issues and sections","tactile perception","Usability"],"title":"Getting Your Hands Dirty Outside the Lab: A Practical Primer for Conducting Wearable Vibrotactile Haptics Research","type":"publication"},{"authors":["Maurício Fontana de Vargas","Antoine Weill-Duflos","Jeremy R Cooperstock"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"b69de09a9006c22445dcec075c1277d1","permalink":"https://antoine.weill-duflos.fr/en/publication/de-vargas-haptic-2019/","publishdate":"2019-10-29T01:20:49.800118Z","relpermalink":"/en/publication/de-vargas-haptic-2019/","section":"publication","summary":"The tactile sense can be used as a channel for general communication, especially in contexts where the visual and auditory modalities are occupied with other tasks or compromised. We propose a new method for communicating generic words through the sense of touch that relies on delivering vibration patterns, representing the phonemes composing the words, to the user's skin through two vibrotactile transducers worn on the forearm. The novelty of this technique is that vibration patterns are created from the audio of the corresponding English phoneme, resulting in vibration patterns that resemble physical characteristics when uttering the phoneme during normal speech. After 100 minutes of training, participants were able to recognize 50 words rendered haptically with an average accuracy of 94.4%. Results support the possibility of using the proposed apparatus in real-world applications.","tags":null,"title":"Haptic Speech Communication Using Stimuli Evocative of Phoneme Production","type":"publication"},{"authors":["Jonathan Cailliez","Mokrane Boudaoud","Abdenbi Mohand-Ousaid","Antoine Weill-Duflos","Sinan Haliyo","Stéphane Régnier"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"542078d0230ada0f9ce5083e96a8af3b","permalink":"https://antoine.weill-duflos.fr/en/publication/cailliez-modeling-2018/","publishdate":"2019-10-29T01:20:49.789117Z","relpermalink":"/en/publication/cailliez-modeling-2018/","section":"publication","summary":"Active force sensors are based on the principle of force balancing using a feedback control. They allow, unlike passive sensors, the measurement of forces in a wide range with nanoNewton resolutions. This capability is fundamental when dealing with the mechanical characterization of samples with a wide range of stiffness. This paper deals with the modeling and the experimental characterization of a new active MEMS based force sensor. This sensor includes folded-flexure type suspensions and a differential comb drive actuation allowing a linear force/voltage relationship. A control oriented electromechanical model is proposed and validated experimentally in static and dynamic operating modes using a stroboscopic measurement system. The sensor has a resonant frequency of 2.2 kHz, and a static passive measurement range of $±$2.45 $μ$N. This work is the first step toward new dynamic measuring capabilities and sensing at the micro/nano-scales when high dynamic, large measurement range and nanoNewton resolution are required.","tags":["Actuators","Mathematical model","feedback","feedback control","microsensors","control oriented electromechanical model","differential comb drive actuation","dynamic operating modes","electromechanical effects","experimental characterization","folded-flexure type suspensions","force balancing principle","force measurement","force sensors","frequency 2.2 kHz","high dynamic measurement range","large measurement range","linear force-voltage relationship","mechanical characterization","Mechanical sensors","microactuators","Micromechanical devices","nanoNewton resolution","passive sensors","Sensor phenomena and characterization","static operating modes","static passive measurement range","stroboscopic measurement system","Suspensions"],"title":"Modeling and Experimental Characterization of an Active MEMS Based Force Sensor","type":"publication"},{"authors":["Antoine Weill-Duflos","Sinan Haliyo","Stéphane Régnier","Vincent Hayward"],"categories":[],"content":"","date":1516115095,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"9ada008cdb42c786d3a22be620bb1aaa","permalink":"https://antoine.weill-duflos.fr/en/publication/2018-br-4668/","publishdate":"2019-10-16T11:04:55-04:00","relpermalink":"/en/publication/2018-br-4668/","section":"publication","summary":"","tags":[],"title":"Interface Haptique à Adaptation de Perception","type":"publication"},{"authors":["Antoine Weill-Duflos","Sinan Haliyo","Stéphane Régnier","Vincent Hayward"],"categories":[],"content":"","date":1514819109,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"5d173e9682246a439651bef13dce7cf9","permalink":"https://antoine.weill-duflos.fr/en/publication/2018-br-4560/","publishdate":"2019-10-16T11:05:09-04:00","relpermalink":"/en/publication/2018-br-4560/","section":"publication","summary":"","tags":[],"title":"Capteur de force sans raideur mécanique","type":"publication"},{"authors":["Feras Al Taha","Pascal E Fortin","Antoine Weill-Duflos","Jeremy R Cooperstock"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"0eb22b70aed9896991e1a2527757ad38","permalink":"https://antoine.weill-duflos.fr/en/publication/al-taha-reversing-2018/","publishdate":"2019-10-29T01:20:49.792118Z","relpermalink":"/en/publication/al-taha-reversing-2018/","section":"publication","summary":"Biased perceptions of others are known to negatively influence the outcomes of social and professional interactions in many regards. Theses biases can be informed by a multitude of non-verbal cues such as voice pitch and voice volume. This project explores how haptic effects, generated from speech, could attenuate listeners' perceived voice-related biases formed from a speaker's voice pitch. Promising preliminary results collected during a decision-making task suggest that the speech to haptic mapping and vibration delivery mechanism employed does attenuate voice-related biases. Accordingly, it is anticipated that such a system could be introduced in the workplace to equalize people's contribution opportunities and to create a more inclusive environment by reversing voice-related biases.","tags":["haptics","speech","affective computing","social computing"],"title":"Reversing Voice-Related Biases Through Haptic Reinforcement","type":"publication"},{"authors":[],"categories":[],"content":"","date":1508173529,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"d60d8a6dd504b93f371bc98783f05283","permalink":"https://antoine.weill-duflos.fr/en/project/haptic-micro-teleoperation/","publishdate":"2017-10-16T13:05:29-04:00","relpermalink":"/en/project/haptic-micro-teleoperation/","section":"project","summary":"","tags":["haptic","micro-robotic"],"title":"Haptic Micro Teleoperation","type":"project"},{"authors":[],"categories":[],"content":"","date":1508173227,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"ec8aa070008cbb70f1d07d45c47846e3","permalink":"https://antoine.weill-duflos.fr/en/project/force-sensors/","publishdate":"2017-10-16T13:00:27-04:00","relpermalink":"/en/project/force-sensors/","section":"project","summary":"","tags":["micro-robotic"],"title":"Force Sensors","type":"project"},{"authors":[],"categories":[],"content":"","date":1508173222,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572213226,"objectID":"8bc59841cc1b12b13ea2932d6c8576e2","permalink":"https://antoine.weill-duflos.fr/en/project/high-fidelity-haptic-devices/","publishdate":"2017-10-16T13:00:22-04:00","relpermalink":"/en/project/high-fidelity-haptic-devices/","section":"project","summary":"","tags":["haptic"],"title":"High Fidelity Haptic Devices","type":"project"},{"authors":["Antoine Weill-Duflos"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"47c05ac3a880e73b1294a47f73cee299","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-interfaces-2017/","publishdate":"2019-10-29T01:20:49.791117Z","relpermalink":"/en/publication/weill-duflos-interfaces-2017/","section":"publication","summary":"Teleoperation opens up new possibilities for interaction with the micro-world. Adequate systems make it possible for human to manipulate elements on microscopic scales. An added haptic feedback provides information crucial for a natural interaction. A bilateral coupling between the subsystems offers the best haptic transparency. This thesis addresses the design of a complete haptic teleoperation chain by focusing on its key elements. Three parts are detailed: The first part describes improvements of the high fidelity one degree of freedom haptic interface designed previously. First, the precision of the forces produced is improved. This improvement is related to the measurement of the motor velocity at high sampling frequencies. Then, the device is precisely caracterized. The second part describes the design of two new force sensors designed specifically for interactions with the micro-world. The forces are measured by compensation. Two approach are observed to expand the frequencies of forces measurable by the sensors. First approach try to reduce the mass, a new sensor on a micrometric scale is built with MEMS technologies. The second approach offer a new design of the sensor. In particular, the stiffness in the guidance is removed. The third part describes the design of a new haptic interface with multiple degrees of freedom. This interface combines the performances of the one degree of freedom interface with a 2D configuration. The key elements of its design are the an air bearing for frictionless guidance and linear induction motors for reduced inertia.","tags":["Haptic device","Capteur de force","Capteurs de force","Couplage bilatéral","Force sensor","Interface haptique","Micro-Monde","Microscopie","Microscopy","Robotique","Systèmes microélectromécaniques","Télécommande","Téléopéation"],"title":"Sensors and devices for a micro-teleoperation system","type":"publication"},{"authors":["Antoine Weill-Duflos","Guillaume Millet","Sinan Haliyo","Stéphane Régnier","Vincent Hayward"],"categories":[],"content":"","date":1496588679,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"6f2f1da2d01bf050966b5679a8f1b203","permalink":"https://antoine.weill-duflos.fr/en/publication/hayward-high-fidelity-2017/","publishdate":"2019-10-16T11:04:39-04:00","relpermalink":"/en/publication/hayward-high-fidelity-2017/","section":"publication","summary":"","tags":[],"title":"High Fidelity Haptic Device","type":"publication"},{"authors":["Alberto Ortega","Antoine Weill-Duflos","Sinan Haliyo","Stéphane Régnier","Vincent Hayward"],"categories":null,"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"9948b31290a5fb8075f141a2cbd57b08","permalink":"https://antoine.weill-duflos.fr/en/publication/ortega-linear-2017/","publishdate":"2019-10-29T01:20:49.785118Z","relpermalink":"/en/publication/ortega-linear-2017/","section":"publication","summary":"This article describes the design of a high-fidelity haptic interface based on a three-axis induction system. Unlike other type of actuators, linear induction motors can provide simultaneously a non-contact drive and a very low inertia. Their integration in a haptic device enables an interface with quasiperfect mechanical transparency. We detail the conception of linear induction motors for a haptic application and experimental results of a proof-of-concept interface driven by them are shown.","tags":["own"],"title":"Linear Induction Actuators for a Haptic Interface: A Quasi-Perfect Transparent Mechanism","type":"publication"},{"authors":["Antoine Weill-Duflos","Abdenbi Mohand-Ousaid","Sinan Haliyo","Stéphane Régnier","Vincent Hayward"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706388498,"objectID":"defc808a78078d76d06d81774599d355","permalink":"https://antoine.weill-duflos.fr/en/publication/weill-duflos-optimizing-2015/","publishdate":"2019-10-29T01:20:49.773118Z","relpermalink":"/en/publication/weill-duflos-optimizing-2015/","section":"publication","summary":"In this paper, the conception and optimization of a new dual-stage haptic device is described. A particular attention is given to the choice of encoder. Compact, consumer grade, but low resolution encoders are particularly used. An issue arising from this particularity is the deterioration of the velocity measurement when Finite Difference method is used. Moreover, when encoders resolution decreases, velocity estimation becomes noisy. From haptic point of view, this noise destroys the realism of the rendered force. To deal with this problem, numerous methods have been proposed to offer a noiseless estimation. Here, advanced methods such as Low-Pass Filter, First Order Adaptive Windowing, Kalman Filter are proposed. Performances of theses methods are verified and experimentally compared to a conventional finite difference method. Here, we show that Kalman filter and First Order Adaptive Windowing offers a good trade-off between estimation and noise rejection.","tags":["Estimation","Finite difference methods","Force","Haptic interfaces","Kalman filter","Kalman filters","Mathematical model","Noise","Torque","Velocity measurement","dual-stage haptic device","encoders resolution","finite difference method","first order adaptive windowing","low resolution encoders","low-pass filter","low-pass filters","noise rejection","optimisation","rendered force","transparency optimization","velocity estimation","own"],"title":"Optimizing Transparency of Haptic Device through Velocity Estimation","type":"publication"}]